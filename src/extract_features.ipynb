{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marco-luzzara/boardgame-complexity-predictor/blob/master/src/extract_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "gOE9-ZKtwDuH",
      "metadata": {
        "id": "gOE9-ZKtwDuH"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "import os\n",
        "WORKING_LOCALLY = bool(os.getenv('WORKING_LOCALLY'))\n",
        "\n",
        "if WORKING_LOCALLY:\n",
        "    DATASET_FILE_PATH = 'data/dataset.csv'\n",
        "else:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    DATASET_FILE_PATH = '/content/drive/My Drive/Projects/IRBoardGameComplexity/dataset.csv'\n",
        "    !pip install spacy-transformers\n",
        "    !python3 -m pip install coreferee==1.3.*\n",
        "    !python3 -m coreferee install en\n",
        "    !python -m spacy download en_core_web_lg\n",
        "    !python -m spacy download en_core_web_trf\n",
        "    !pip install git+https://github.com/LIAAD/yake\n",
        "    !pip install rake-nltk\n",
        "    clear_output(wait=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3aa4a086-aa20-4def-b17a-3b4ff4fad93f",
      "metadata": {
        "id": "3aa4a086-aa20-4def-b17a-3b4ff4fad93f"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "## +++++++++++ with fastcoref\n",
        "# from fastcoref import spacy_component\n",
        "# nlp = spacy.load(\"en_core_web_sm\", exclude=[\"parser\", \"lemmatizer\", \"ner\", \"textcat\"])\n",
        "# nlp.add_pipe(\"fastcoref\")\n",
        "#              #config={'model_architecture': 'LingMessCoref', 'model_path': 'biu-nlp/lingmess-coref'})\n",
        "\n",
        "# # to remove tqdm progress bar: https://stackoverflow.com/questions/37091673/silence-tqdms-output-while-running-tests-or-running-the-code-via-cron\n",
        "# from tqdm.auto import tqdm\n",
        "# from functools import partialmethod\n",
        "# tqdm.__init__ = partialmethod(tqdm.__init__, disable=True, ncols=0, nrows=0, gui=False, bar_format='', leave=False)\n",
        "\n",
        "## +++++++++++ with coreferee\n",
        "import coreferee\n",
        "nlp = spacy.load('en_core_web_trf')\n",
        "nlp.add_pipe(\"coreferee\")\n",
        "\n",
        "clear_output(wait=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a4bcea26-c1a3-45fb-845e-98cae3073e85",
      "metadata": {
        "id": "a4bcea26-c1a3-45fb-845e-98cae3073e85",
        "outputId": "b25ba586-3d36-4e1a-a79f-45b6f7134f7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-11-22 00:07:42,257 bgg_predict  DEBUG    test\n",
            "DEBUG:bgg_predict:test\n"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "\n",
        "logger = logging.getLogger('bgg_predict')\n",
        "logger.handlers.clear()\n",
        "handler = logging.StreamHandler()\n",
        "formatter = logging.Formatter(\n",
        "        '%(asctime)s %(name)-12s %(levelname)-8s %(message)s')\n",
        "handler.setFormatter(formatter)\n",
        "logger.addHandler(handler)\n",
        "logger.setLevel(logging.DEBUG)\n",
        "\n",
        "logger.debug('test')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "regex_mail = re.compile(r'\\w+(?:\\.\\w+)*?@\\w+(?:\\.\\w+)+')\n",
        "# modified from https://stackoverflow.com/a/163684/5587393\n",
        "regex_link = re.compile(r'(?:\\b(?:(?:https?|ftp|file)://|www))[-A-Za-z0-9+&@#/%?=~_|!:,.;]+[-A-Za-z0-9+&@#%=~_|]')\n",
        "# in a sentence there must be at least 4 words of length 2 each\n",
        "regex_at_least_4_words_in_sentence = re.compile(r'^(?=.*?(?:[,:;()]?[a-zA-Z]{2,}[,:;()]?(?: |$)[^a-zA-Z]*?){4,})')\n",
        "# a string like \"first.Second\" could be misinterpreted by the tokenizer as a single token\n",
        "# with the regex it becomes \"first. Second\"\n",
        "regex_distance_between_period_and_following_word = re.compile(r'\\.(?!\\s|$)')\n",
        "# compress consecutive whitespaces\n",
        "regex_multiple_spaces = re.compile(r'\\s{2,}')\n",
        "# interrupted words usually have a \"- \" at the end before the new line, 'inter- rupted' -> 'interrupted'\n",
        "# NOTE: must be after whitespace compression\n",
        "regex_interrupted_word = re.compile(r'([a-zA-Z])- ')\n",
        "# remove page numbers, that are usually enclosed in characters like = or -, for example \"-12-\"\n",
        "regex_consecutive_meaningless_chars = re.compile(r'[^\\.a-zA-Z0-9\\s()]{2,} *(?:\\d+)?|(?P<prepage>[^a-zA-Z\\s\\d\\.])\\d+(?P=prepage)')\n",
        "# remove paragraphs id, '1.2.3' -> ''\n",
        "regex_dot_separated_digits = re.compile(r'(?:\\d+\\.)+\\d+')\n",
        "# remove meaningless chars after sentence start, '. (- start' -> '. start'\n",
        "regex_clean_start = re.compile(r'\\.(\\s?)[^a-zA-Z\\s]+')\n",
        "\n",
        "def clean_from_short_sentences(text: str) -> str:\n",
        "    return '.'.join(sentence for sentence in text.split('.') if regex_at_least_4_words_in_sentence.match(sentence) is not None)\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    for clean_function in [lambda x: regex_mail.sub('', x),\n",
        "                           lambda x: regex_link.sub('', x),\n",
        "                           lambda x: regex_dot_separated_digits.sub('', x),\n",
        "                           lambda x: regex_consecutive_meaningless_chars.sub('', x),\n",
        "                           lambda x: regex_clean_start.sub(r'.\\1', x),\n",
        "                           # everything that is remove should be placed before this line so that \n",
        "                           # eventual spaces are compressed with regex_multiple_space\n",
        "                           lambda x: regex_multiple_spaces.sub(' ', x),\n",
        "                           lambda x: regex_interrupted_word.sub(r'\\1', x),\n",
        "                           lambda x: clean_from_short_sentences(x),\n",
        "                           lambda x: regex_distance_between_period_and_following_word.sub('. ', x)]:\n",
        "        text = clean_function(text)\n",
        "    return text\n",
        "\n",
        "test_text = 'this is a test (me@gmail.it) -12- that wi-  ll be   cleaned. with 2 5 6 not valid. two sentences is good enough http://or.not.'\n",
        "cleaned_text = clean_text(test_text)\n",
        "print(cleaned_text)\n",
        "assert cleaned_text == 'this is a test () that will be cleaned. two sentences is good enough '"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBHkUGAsukWJ",
        "outputId": "33624123-104e-411c-a31a-6b248d16f554"
      },
      "id": "bBHkUGAsukWJ",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is a test () that will be cleaned. two sentences is good enough \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "def remove_columns_prefix(df: pd.DataFrame) -> None:\n",
        "    '''remove prefix 'info.' from the columns of df'''\n",
        "    df.rename(columns=lambda c: c.rsplit('.', 1)[-1], inplace=True)\n",
        "\n",
        "def get_df_with_docs(file_path: str, nrows=None, skiprows=1) -> pd.DataFrame:\n",
        "    ''' get a dataframe containing nrows and skipping the first `skiprows` (including the header)'''\n",
        "    df_dataset = pd.read_csv(file_path, converters={ 'info.family': ast.literal_eval }, \n",
        "                             nrows=nrows, skiprows=range(1, skiprows))\n",
        "    remove_columns_prefix(df_dataset)\n",
        "    return df_dataset\n",
        "\n",
        "def get_document_by_line(file_path: str, line: int) -> str:\n",
        "    ''' the line includes the header too '''\n",
        "    # range from 1 is used to keep the first row https://stackoverflow.com/a/27325729/5587393\n",
        "    df = get_df_with_docs(file_path, 1, line - 1)\n",
        "    return df['rulebook'].iloc[0]\n",
        "\n",
        "def get_document_by_id(file_path: str, id: int) -> str:\n",
        "     with pd.read_csv(file_path, chunksize=1, converters={ 'family': ast.literal_eval }) as reader:\n",
        "        while True:\n",
        "            df = next(reader)\n",
        "            bg_id = df['info.id'].iloc[0]\n",
        "            if bg_id == id:\n",
        "                return df['rulebook'].iloc[0]\n",
        "\n",
        "assert get_document_by_id(DATASET_FILE_PATH, 2310) == get_document_by_line(DATASET_FILE_PATH, 40)"
      ],
      "metadata": {
        "id": "VepMko8FPiyw"
      },
      "id": "VepMko8FPiyw",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "361b1290-00e4-42f3-85a4-badadb8d574f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "361b1290-00e4-42f3-85a4-badadb8d574f",
        "outputId": "3b4aaf49-7de6-4d5c-a61a-1973bddc2f64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0], [1, 1, 2], [2, 3]]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from typing import Tuple\n",
        "\n",
        "def get_sentences_from_clusters(clusters: List[List[Tuple[int, int]]], sentences: List[Sentence]) -> List[List[int]]:\n",
        "    # + sentences[0] because sentences are built from the entire text and not from the current group\n",
        "    clusters_on_sentences = [[next(filter(lambda x: x[1].does_include_pos(entity[0] + sentences[0].start), enumerate(sentences)))[0] \n",
        "                              for entity in cluster]\n",
        "                             for cluster in clusters]\n",
        "\n",
        "    return clusters_on_sentences\n",
        "\n",
        "# text = 'Alice goes down the rabbit hole. Where she would discover a new reality beyond her expectations.'\n",
        "# sentences = get_sentences_from_text(text)\n",
        "# clusters = [[(0, 5), (39, 42), (79, 82)]]\n",
        "sentences = [Sentence(content=' A boom unit is destroyed when it has received 5 floatation hits,  and is removed from play, clearing the hex for unobstructed vessel  movement', start=65348, end=65490), \n",
        "             Sentence(content=' If a boom unit destroyed on the same game turn it is attacked, the  attacking vessel (A', start=65492, end=65579), \n",
        "             Sentence(content=' is not subject to a die roll on the Vessel  Fouling Table (Combat Table No', start=65581, end=65655), \n",
        "             Sentence(content=' 13) and continues its movement', start=65657, end=65687)]\n",
        "clusters = [[(8, 11), (31, 32)], [(192, 193), (231, 232), (308, 308)], [(306, 307), (328, 330)]]        \n",
        "get_sentences_from_clusters(clusters, sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2e53dc33-31ba-4e04-80e6-dc645714fe60",
      "metadata": {
        "id": "2e53dc33-31ba-4e04-80e6-dc645714fe60"
      },
      "outputs": [],
      "source": [
        "from typing import List, Set\n",
        "from itertools import groupby\n",
        "from operator import itemgetter\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse.csgraph import connected_components\n",
        "\n",
        "def get_rule_groups_from_sentence_clusters(sentences: List[Sentence], sentence_clusters: List[List[int]]) -> List[List[int]]:\n",
        "    def normalize_group(group: Set[int]) -> List[List[int]]:\n",
        "        '''each group could contain multiple consecutive sublists. this method split these sublists'''\n",
        "        res = []\n",
        "\n",
        "        # https://stackoverflow.com/a/23861347/5587393\n",
        "        for k, g in groupby(enumerate(sorted(list(group))), lambda x: x[0] - x[1]):\n",
        "            res.append(list(map(itemgetter(1), g)))\n",
        "\n",
        "        return res\n",
        "    # the graph is built as a directed sparse graph where the first element of each cluster\n",
        "    # is connected to the other elements in the same cluster\n",
        "    graph = [[0 for _ in range(len(sentences))] for __ in range(len(sentences))]\n",
        "    for cluster in sentence_clusters:\n",
        "        for sentence in cluster[1:]:\n",
        "            graph[cluster[0]][sentence] = 1\n",
        "\n",
        "    # find the connected components of the graph created from the clusters returned after coref     \n",
        "    graph = csr_matrix(graph)\n",
        "    n_components, labels = connected_components(csgraph=graph, directed=False, return_labels=True)\n",
        "    groups = [set() for _ in range(n_components)]\n",
        "    for i, label in enumerate(labels):\n",
        "        groups[label].add(i)\n",
        "\n",
        "    return [norm_group for group in groups for norm_group in normalize_group(group)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "4c83a628-762c-4084-8d9c-4b64a615fe09",
      "metadata": {
        "id": "4c83a628-762c-4084-8d9c-4b64a615fe09",
        "outputId": "962e7295-8f45-4dc0-80dc-8714bf5510e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(9, 10), (31, 33), (41, 45), (69, 70), (76, 78)],\n",
              " [(35, 38), (65, 66)],\n",
              " [(69, 70), (93, 96), (116, 119), (148, 151)],\n",
              " [(134, 138), (163, 169)]]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from typing import List, Tuple\n",
        "def convert_result_to_cluster(result, pipeline) -> List[List[Tuple[int, int]]]:\n",
        "    component_names = [x[0] for x in pipeline]\n",
        "    if 'coreferee' in component_names:\n",
        "        return [[(result[entity[0]].idx, result[entity[0]].idx + len(result[entity[0]]) - 1) \n",
        "                 for entity in chain] for chain in result._.coref_chains]\n",
        "    elif 'fastcoref' in component_names:\n",
        "        return result._.coref_clusters\n",
        "\n",
        "result = nlp(\"Although he was very busy with his work, Peter had had enough of it. He and his wife decided they needed a holiday. They travelled to Spain because they loved the country very much.\")\n",
        "convert_result_to_cluster(result, nlp.pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FWKfCPyrdjis",
      "metadata": {
        "id": "FWKfCPyrdjis"
      },
      "outputs": [],
      "source": [
        "from typing import List, Tuple\n",
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "def get_rules(text: str) -> List[str]:\n",
        "    text = clean_text(text)\n",
        "    sentences = get_sentences_from_text(text)\n",
        "    \n",
        "    GROUP_STEP_OFFSET = 2\n",
        "    # I create groups of 4 sentences to speed up the process of finding connected sentences\n",
        "    # and to make sure to find connected sentences not immediately adjacent\n",
        "    sentences_groups = [sentences[i:min(i+4, len(sentences))] for i in range(0, len(sentences) - 2, GROUP_STEP_OFFSET)]\n",
        "    doc_groups = nlp.pipe(['.'.join(map(lambda s: s.content, group)) for group in sentences_groups])\n",
        "\n",
        "    cluster_groups = []\n",
        "    for i, group in enumerate(sentences_groups):\n",
        "        group_text = next(doc_groups)\n",
        "        group_coref_clusters = convert_result_to_cluster(group_text, nlp.pipeline)\n",
        "        group_sentence_clusters = get_sentences_from_clusters(group_coref_clusters, group)\n",
        "        # + i * GROUP_STEP_OFFSET to retrieve the actual index of the sentence\n",
        "        cluster_groups.extend([sentence_id + i * GROUP_STEP_OFFSET for sentence_id in gsc] \n",
        "                               for gsc in group_sentence_clusters)\n",
        "        \n",
        "    rule_groups = get_rule_groups_from_sentence_clusters(sentences, cluster_groups)                                                                                \n",
        "    \n",
        "    return ['. '.join([sentences[s_index].content for s_index in group]) for group in rule_groups]\n",
        "\n",
        "text = get_document_by_id(DATASET_FILE_PATH, 24770)\n",
        "rules = get_rules(text)\n",
        "\n",
        "rules"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "from collections import Counter, defaultdict\n",
        "from typing import List, Dict\n",
        "\n",
        "def filter_tokens_as_components(doc: spacy.tokens.Doc) -> Dict[str, List[spacy.tokens.Token]]:\n",
        "    tokens_dict = defaultdict(list)\n",
        "\n",
        "    for token in doc:\n",
        "        if len(token) >= 3 and \\\n",
        "            token.pos_ in ['NOUN', 'PROPN'] and \\\n",
        "            token.dep_ in ['nsubj', 'dobj', 'nsubjpass', 'pobj', 'compound']:\n",
        "            tokens_dict[token.lemma_.lower()].append(token)\n",
        "           \n",
        "    return tokens_dict\n",
        "\n",
        "def find_n_most_common_nouns(n, docs: List[spacy.tokens.Doc]) -> List[str]:\n",
        "    docs_sets = [set(filter_tokens_as_components(doc).keys())\n",
        "                 for doc in docs]\n",
        "    all_tokens_from_docs = itertools.chain(*docs_sets)\n",
        "    tokens_counter = Counter(all_tokens_from_docs)\n",
        "    return tokens_counter.most_common(n)\n",
        "    \n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "df_dataset = get_df_with_docs(DATASET_FILE_PATH, 10, 50)\n",
        "docs = nlp.pipe(map(clean_text, df_dataset['rulebook'].values))\n",
        "\n",
        "find_n_most_common_nouns(10, docs)"
      ],
      "metadata": {
        "id": "w-JVFrfg4BwA"
      },
      "id": "w-JVFrfg4BwA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "from collections import namedtuple\n",
        "from spacy.matcher import Matcher, DependencyMatcher\n",
        "\n",
        "LuckMetrics = namedtuple('LuckMetrics', ['dice_based', 'drawing_based', 'shuffling_based', 'random_based'])\n",
        "\n",
        "def get_luck_matches(doc: spacy.tokens.Doc) -> LuckMetrics:\n",
        "    # ---------- random ----------\n",
        "    random_matcher = Matcher(doc.vocab)\n",
        "    random_patterns_match = [\n",
        "        [{\"LEMMA\": { \"IN\": [\"random\", \"randomly\"]}}]\n",
        "    ]\n",
        "    random_matcher.add(\"random\", random_patterns_match)\n",
        "\n",
        "    # ---------- shuffle ----------\n",
        "    shuffle_matcher = Matcher(doc.vocab)\n",
        "    shuffle_patterns_match = [\n",
        "        [{\"LEMMA\": \"shuffle\", \"POS\": \"VERB\"}]\n",
        "    ]\n",
        "    shuffle_matcher.add(\"shuffle\", shuffle_patterns_match)\n",
        "\n",
        "    # ---------- card drawing ----------\n",
        "    drawing_matcher = DependencyMatcher(doc.vocab)    \n",
        "    drawing_patterns = [\n",
        "        [\n",
        "            {\n",
        "                \"RIGHT_ID\": \"drawing\",\n",
        "                \"RIGHT_ATTRS\": {\"LEMMA\": \"draw\", \"POS\": \"VERB\"}\n",
        "            },\n",
        "            {\n",
        "                \"LEFT_ID\": \"drawing\",\n",
        "                \"REL_OP\": \">\",\n",
        "                \"RIGHT_ID\": \"card\",\n",
        "                \"RIGHT_ATTRS\": {\n",
        "                    \"LEMMA\": \"card\",\n",
        "                    \"POS\": \"NOUN\", \n",
        "                    \"DEP\": { \"IN\": ['dobj', 'nsubjpass', 'compound'] }\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "    ]\n",
        "    drawing_matcher.add(\"drawing\", drawing_patterns)\n",
        "    # ---------- dice rolling ----------\n",
        "    dice_matcher = DependencyMatcher(doc.vocab)    \n",
        "    dice_patterns = [\n",
        "        [\n",
        "            {\n",
        "                \"RIGHT_ID\": \"rolling\",\n",
        "                \"RIGHT_ATTRS\": {\"LEMMA\": { \"IN\": [\"use\", \"throw\", \"roll\"]}, \"POS\": \"VERB\"}\n",
        "            },\n",
        "            {\n",
        "                \"LEFT_ID\": \"rolling\",\n",
        "                \"REL_OP\": \">\",\n",
        "                \"RIGHT_ID\": \"dice_or_die\",\n",
        "                \"RIGHT_ATTRS\": {\n",
        "                    \"LEMMA\": { \"IN\": [\"die\", \"dice\"]},\n",
        "                    \"POS\": \"NOUN\", \n",
        "                    \"DEP\": { \"IN\": ['nsubj', 'dobj', 'nsubjpass', 'compound'] }\n",
        "                }\n",
        "            }\n",
        "        ],\n",
        "        [\n",
        "            {\n",
        "                \"RIGHT_ID\": \"rolling\",\n",
        "                \"RIGHT_ATTRS\": {\"LEMMA\": { \"IN\": [\"use\", \"throw\", \"roll\"]}, \"POS\": \"VERB\"}\n",
        "            },\n",
        "            {\n",
        "                \"LEFT_ID\": \"rolling\",\n",
        "                \"REL_OP\": \">\",\n",
        "                \"RIGHT_ID\": \"number\",\n",
        "                \"RIGHT_ATTRS\": {\n",
        "                    \"IS_DIGIT\": True, \n",
        "                    \"DEP\": { \"IN\": ['dobj'] }\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "    ]\n",
        "    dice_matcher.add(\"diceroll\", dice_patterns)\n",
        "\n",
        "    dice_matches = dice_matcher(doc) \n",
        "    draw_matches = drawing_matcher(doc)\n",
        "    shuffle_matches = shuffle_matcher(doc)\n",
        "    random_matches = random_matcher(doc)\n",
        "    \n",
        "    return LuckMetrics(len(dice_matches), len(draw_matches), len(shuffle_matches), len(random_matches))\n",
        "\n",
        "# text = get_document_by_line(DATASET_FILE_PATH, 153)\n",
        "text = '''you could use the random choice or randomly pick a card. some dice are thrown. next you roll 12 when the dice roll'''\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(text)\n",
        "print([token.lemma_ for token in doc])\n",
        "print(get_luck_matches(doc))\n",
        "\n",
        "displacy.render(doc, style='dep', jupyter=True)"
      ],
      "metadata": {
        "id": "Ayy4X1vaYYCj",
        "outputId": "855339e6-16a5-4e24-e907-49fe46f6ef38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        }
      },
      "id": "Ayy4X1vaYYCj",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['you', 'could', 'use', 'the', 'random', 'choice', 'or', 'randomly', 'pick', 'a', 'card', '.', 'some', 'dice', 'be', 'throw', '.', 'next', 'you', 'roll', '12', 'when', 'the', 'dice', 'roll']\n",
            "LuckMetrics(dice_based=3, drawing_based=0, shuffling_based=0, random_based=2)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"c3c041c50c4d43c5a0fd9498039cf76b-0\" class=\"displacy\" width=\"4075\" height=\"574.5\" direction=\"ltr\" style=\"max-width: none; height: 574.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">you</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">could</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">use</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">random</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">choice</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">or</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">CCONJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">randomly</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">pick</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">card.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">some</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">dice</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">are</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">thrown.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">next</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">you</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">roll</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">12</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3375\">when</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3375\">SCONJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3550\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3550\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3725\">dice</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3725\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3900\">roll</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3900\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-0\" stroke-width=\"2px\" d=\"M70,439.5 C70,264.5 385.0,264.5 385.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,441.5 L62,429.5 78,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-1\" stroke-width=\"2px\" d=\"M245,439.5 C245,352.0 380.0,352.0 380.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,441.5 L237,429.5 253,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-2\" stroke-width=\"2px\" d=\"M595,439.5 C595,264.5 910.0,264.5 910.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,441.5 L587,429.5 603,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-3\" stroke-width=\"2px\" d=\"M770,439.5 C770,352.0 905.0,352.0 905.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M770,441.5 L762,429.5 778,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-4\" stroke-width=\"2px\" d=\"M420,439.5 C420,177.0 915.0,177.0 915.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M915.0,441.5 L923.0,429.5 907.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-5\" stroke-width=\"2px\" d=\"M420,439.5 C420,89.5 1095.0,89.5 1095.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1095.0,441.5 L1103.0,429.5 1087.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-6\" stroke-width=\"2px\" d=\"M1295,439.5 C1295,352.0 1430.0,352.0 1430.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1295,441.5 L1287,429.5 1303,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-7\" stroke-width=\"2px\" d=\"M420,439.5 C420,2.0 1450.0,2.0 1450.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1450.0,441.5 L1458.0,429.5 1442.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-8\" stroke-width=\"2px\" d=\"M1645,439.5 C1645,352.0 1780.0,352.0 1780.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1645,441.5 L1637,429.5 1653,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-9\" stroke-width=\"2px\" d=\"M1470,439.5 C1470,264.5 1785.0,264.5 1785.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1785.0,441.5 L1793.0,429.5 1777.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-10\" stroke-width=\"2px\" d=\"M1995,439.5 C1995,352.0 2130.0,352.0 2130.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1995,441.5 L1987,429.5 2003,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-11\" stroke-width=\"2px\" d=\"M2170,439.5 C2170,264.5 2485.0,264.5 2485.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubjpass</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2170,441.5 L2162,429.5 2178,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-12\" stroke-width=\"2px\" d=\"M2345,439.5 C2345,352.0 2480.0,352.0 2480.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">auxpass</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2345,441.5 L2337,429.5 2353,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-13\" stroke-width=\"2px\" d=\"M2695,439.5 C2695,264.5 3010.0,264.5 3010.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2695,441.5 L2687,429.5 2703,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-14\" stroke-width=\"2px\" d=\"M2870,439.5 C2870,352.0 3005.0,352.0 3005.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2870,441.5 L2862,429.5 2878,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-15\" stroke-width=\"2px\" d=\"M3045,439.5 C3045,352.0 3180.0,352.0 3180.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3180.0,441.5 L3188.0,429.5 3172.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-16\" stroke-width=\"2px\" d=\"M3395,439.5 C3395,264.5 3885.0,264.5 3885.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3395,441.5 L3387,429.5 3403,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-17\" stroke-width=\"2px\" d=\"M3570,439.5 C3570,352.0 3705.0,352.0 3705.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3570,441.5 L3562,429.5 3578,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-18\" stroke-width=\"2px\" d=\"M3745,439.5 C3745,352.0 3880.0,352.0 3880.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3745,441.5 L3737,429.5 3753,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-19\" stroke-width=\"2px\" d=\"M3045,439.5 C3045,177.0 3890.0,177.0 3890.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c3c041c50c4d43c5a0fd9498039cf76b-0-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advcl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3890.0,441.5 L3898.0,429.5 3882.0,429.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "import coreferee\n",
        "\n",
        "def _get_new_token_from_resolve(token: spacy.tokens.Token, \n",
        "                                chains: coreferee.data_model.ChainHolder) -> spacy.tokens.Token:\n",
        "    resolved_token = chains.resolve(token)\n",
        "    return token.text_with_ws if resolved_token is None \\\n",
        "                              else ' and '.join([res_token.text_with_ws for res_token in resolved_token])   \n",
        "\n",
        "def _process_doc_for_coref(doc: spacy.tokens.Doc) -> str:\n",
        "    replacement_tokens = []\n",
        "    chains = doc._.coref_chains\n",
        "    new_doc_tokens_text = [_get_new_token_from_resolve(token, chains) for token in doc]\n",
        "\n",
        "    return ''.join(new_doc_tokens_text)\n",
        "\n",
        "def preprocess_texts(texts: List[str]) -> List[str]:\n",
        "    nlp = spacy.load('en_core_web_trf')\n",
        "    nlp.add_pipe(\"coreferee\")\n",
        "\n",
        "    texts = [clean_text(text) for text in texts]\n",
        "    docs = nlp.pipe(texts)\n",
        "\n",
        "    return [_process_doc_for_coref(doc) for doc in docs]\n",
        "        \n",
        "# text = get_document_by_line(DATASET_FILE_PATH, 40)\n",
        "text = '''Although he was very busy with his work, the magical Peter had had enough of it. \n",
        "    He and his wife decided they needed a holiday. \n",
        "    this couple travelled to Spain because it loves the country very much.'''\n",
        "preprocess_texts([text])"
      ],
      "metadata": {
        "id": "jpT4BvSfFWTd"
      },
      "id": "jpT4BvSfFWTd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(clean_text(get_document_by_line(DATASET_FILE_PATH, 155)))\n",
        "doc.text\n",
        "# print(doc[12].dep_)\n",
        "#doc.text.find('Tinners Trail Player')"
      ],
      "metadata": {
        "id": "XojL4wsdmTqI"
      },
      "id": "XojL4wsdmTqI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "from typing import List, Set, Dict\n",
        "from rake_nltk import Rake\n",
        "from nltk.util import ngrams\n",
        "import yake\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "\n",
        "# stopwords = nlp.Defaults.stop_words\n",
        "# rake = Rake(stopwords=stopwords, punctuations={ c for c in punctuation },\n",
        "#             sentence_tokenizer=lambda txt: txt.split('.'))\n",
        "\n",
        "regex_word_within_boundaries = re.compile(r'\\b')\n",
        "MIN_TOKEN_TO_BE_CONSIDERED_COMPONENT = 4\n",
        "MAX_COMPONENTS = 100\n",
        "\n",
        "def _get_ngrams_components(doc: spacy.tokens.Doc, \\\n",
        "                           components: Dict[str, List[spacy.tokens.Token]],\n",
        "                           n_grams: int):\n",
        "    pass\n",
        "\n",
        "\n",
        "def _get_bg_components_by_deps_inspection(doc: spacy.tokens.Doc) -> Dict[str, List[int]]:\n",
        "    words_to_leave_out = ['beginning', 'board', 'book', 'case', 'clarification', 'design', \n",
        "                          'effect', 'end', 'example', 'case', 'game', 'number', \n",
        "                          'overview', 'order', 'play', 'player', 'purpose', 'reference',\n",
        "                          'result', 'rule', 'rulebook', 'section', 'set', 'setup', 'summary', \n",
        "                          'start', 'step', 'thing', 'type', 'time', 'total', 'use', 'value', 'version', 'way']\n",
        "\n",
        "    possible_components = dict(filter(lambda token: token[0] not in words_to_leave_out and \n",
        "                                      len(token[1]) >= MIN_TOKEN_TO_BE_CONSIDERED_COMPONENT, \n",
        "                                  filter_tokens_as_components(doc).items()))\n",
        "    return possible_components\n",
        "\n",
        "# def _get_lemmas_given_keywords_group(group: str, doc: spacy.tokens.Doc) -> List[str]:\n",
        "#     kw_match = re.search(r'\\b' + group + '\\\\b', doc.text)\n",
        "#     if kw_match is None:\n",
        "#         return []\n",
        "\n",
        "#     group_span = doc.char_span(kw_match.start(0), kw_match.end(0))\n",
        "#     return [token.lemma_.lower() for token in group_span]\n",
        "\n",
        "# def _get_bg_components_by_keyword_analysis(doc: spacy.tokens.Doc, max_keywords: int) -> List[str]:\n",
        "#     kw_extractor = yake.KeywordExtractor(top=max_keywords)\n",
        "#     keywords_info = kw_extractor.extract_keywords(doc.text)\n",
        "#     keyword_groups = [keyword_info[0] for keyword_info in keywords_info if keyword_info[1] < 0.1]\n",
        "\n",
        "#     return [lemma for keyword_group in keyword_groups \n",
        "#             for lemma in _get_lemmas_given_keywords_group(keyword_group, doc)]\n",
        "\n",
        "def get_bg_components(doc: spacy.tokens.Doc) -> Dict[str, List[int]]:\n",
        "    components_by_deps = _get_bg_components_by_deps_inspection(doc)\n",
        "    # print(components_by_deps)\n",
        "    # components_by_kws = _get_bg_components_by_keyword_analysis(doc, len(components_by_deps))\n",
        "    # print(components_by_kws)\n",
        "\n",
        "    # return set(components_by_deps).intersection(set(components_by_kws))\n",
        "    return components_by_deps\n",
        "\n",
        "def get_doc_variance(doc: spacy.tokens.Doc, components_dict: Dict[str, List[int]]) -> float:\n",
        "    '''variance measures how components interleave in the text. This could mean that rules involve\n",
        "    many components and are therefore more complex. variancy is computed using `np.var` on each\n",
        "    component list. the results are normalized by multiplicating for the frequency of the component.\n",
        "    eventually the partial variances are summed together and the result normalized with the \n",
        "    total numbers of tokens.'''\n",
        "    tokens_count = sum(len(token_list) for token_list in components_dict.values())\n",
        "    return sum((len(tokens) / tokens_count) * np.var([token.i for token in tokens])\n",
        "        for tokens in components_dict.values()) / len((doc))\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(clean_text(get_document_by_line(DATASET_FILE_PATH, 138)))\n",
        "print(len(doc.text))\n",
        "components = get_bg_components(doc)\n",
        "print(components)\n",
        "print(get_doc_variance(doc, components))\n",
        "\n",
        "\n",
        "# rake.extract_keywords_from_text(doc.text)\n",
        "# print(rake.get_word_frequency_distribution())\n",
        "# for keyword in rake.get_ranked_phrases_with_scores():\n",
        "#     print(keyword)\n",
        "# print(rake.get_word_degrees())"
      ],
      "metadata": {
        "id": "TKh5Jf-xovbn"
      },
      "id": "TKh5Jf-xovbn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d6596cd-3fd1-4e50-9dce-e6c333667182",
      "metadata": {
        "id": "7d6596cd-3fd1-4e50-9dce-e6c333667182"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple\n",
        "import pandas as pd\n",
        "import ast\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def get_rules_features(id: int, doc: spacy.tokens.Doc) -> Tuple[int, float]:\n",
        "    logger.info(f'processing board game {id}')\n",
        "    rulebook_len = len(doc)\n",
        "    bg_components = get_bg_components(doc)\n",
        "    print(bg_components)\n",
        "\n",
        "    return 0, 0\n",
        "    # rules = get_rules(text)\n",
        "    # rule_count = len(rules)\n",
        "    # return rule_count, len(text) / rule_count\n",
        "\n",
        "def apply_for_rulebook_features(row, docs_dict):\n",
        "    next_doc_info = next(docs_dict)\n",
        "    assert next_doc_info[0] == row.id\n",
        "    return pd.Series(get_rules_features(row.id, next_doc_info[1]), \n",
        "                     index=['rule_count', 'avg_rule_len'])\n",
        "\n",
        "PROCESSED_DATASET_FILE_PATH = 'data/processed_dataset.csv' if WORKING_LOCALLY \\\n",
        "    else '/content/drive/My Drive/Projects/IRBoardGameComplexity/processed_dataset.csv'\n",
        "\n",
        "# ast.literal_eval converts the family column string into a python array\n",
        "# with pd.read_csv(DATASET_FILE_PATH, chunksize=5, converters={ 'info.family': ast.literal_eval }) as reader:\n",
        "#     for df in reader:\n",
        "df_dataset = pd.read_csv(DATASET_FILE_PATH, converters={ 'info.family': ast.literal_eval }, nrows=1)\n",
        "remove_columns_prefix(df_dataset)\n",
        "docs_dict = zip(df_dataset['id'].values, \n",
        "                nlp.pipe(map(clean_text, df_dataset['rulebook'].values)))\n",
        "\n",
        "df_rules_features = df_dataset.apply(lambda x: apply_for_rulebook_features(x, docs_dict),\n",
        "                                     axis='columns')\n",
        "df_features = df_dataset[['averageweight', 'playingtime', 'family']].join(df_rules_features)\n",
        "        \n",
        "# one-hot encoding \"family\" field \n",
        "# from https://stackoverflow.com/questions/71401193/one-hot-encoding-in-python-for-array-values-in-a-dataframe\n",
        "df_features = df_features.join(df_features.pop('family').apply('|'.join).str.get_dummies())\n",
        "df_features.head()\n",
        "\n",
        "# df_features.to_csv(PROCESSED_DATASET_FILE_PATH, header=True, index=False, mode='w')    \n",
        "# if not WORKING_LOCALLY:\n",
        "#     drive.flush_and_unmount()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marco-luzzara/boardgame-complexity-predictor/blob/master/src/extract_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "gOE9-ZKtwDuH",
      "metadata": {
        "id": "gOE9-ZKtwDuH"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "import os\n",
        "WORKING_LOCALLY = bool(os.getenv('WORKING_LOCALLY'))\n",
        "\n",
        "if WORKING_LOCALLY:\n",
        "    DATASET_FILE_PATH = 'data/dataset.csv'\n",
        "else:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    DATASET_FILE_PATH = '/content/drive/My Drive/Projects/IRBoardGameComplexity/dataset.csv'\n",
        "    !pip install spacy-transformers\n",
        "    !python3 -m pip install coreferee==1.3.*\n",
        "    !python3 -m coreferee install en\n",
        "    !python -m spacy download en_core_web_lg\n",
        "    !python -m spacy download en_core_web_trf\n",
        "    !pip install git+https://github.com/LIAAD/yake\n",
        "    !pip install rake-nltk\n",
        "    clear_output(wait=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3aa4a086-aa20-4def-b17a-3b4ff4fad93f",
      "metadata": {
        "id": "3aa4a086-aa20-4def-b17a-3b4ff4fad93f"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "## +++++++++++ with fastcoref\n",
        "# from fastcoref import spacy_component\n",
        "# nlp = spacy.load(\"en_core_web_sm\", exclude=[\"parser\", \"lemmatizer\", \"ner\", \"textcat\"])\n",
        "# nlp.add_pipe(\"fastcoref\")\n",
        "#              #config={'model_architecture': 'LingMessCoref', 'model_path': 'biu-nlp/lingmess-coref'})\n",
        "\n",
        "# # to remove tqdm progress bar: https://stackoverflow.com/questions/37091673/silence-tqdms-output-while-running-tests-or-running-the-code-via-cron\n",
        "# from tqdm.auto import tqdm\n",
        "# from functools import partialmethod\n",
        "# tqdm.__init__ = partialmethod(tqdm.__init__, disable=True, ncols=0, nrows=0, gui=False, bar_format='', leave=False)\n",
        "\n",
        "## +++++++++++ with coreferee\n",
        "import coreferee\n",
        "nlp = spacy.load('en_core_web_trf')\n",
        "nlp.add_pipe(\"coreferee\")\n",
        "\n",
        "clear_output(wait=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a4bcea26-c1a3-45fb-845e-98cae3073e85",
      "metadata": {
        "id": "a4bcea26-c1a3-45fb-845e-98cae3073e85",
        "outputId": "0f455090-a368-4081-98b1-673b40fb534e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-11-22 22:10:15,756 bgg_predict  DEBUG    test\n",
            "DEBUG:bgg_predict:test\n"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "\n",
        "logger = logging.getLogger('bgg_predict')\n",
        "logger.handlers.clear()\n",
        "handler = logging.StreamHandler()\n",
        "formatter = logging.Formatter(\n",
        "        '%(asctime)s %(name)-12s %(levelname)-8s %(message)s')\n",
        "handler.setFormatter(formatter)\n",
        "logger.addHandler(handler)\n",
        "logger.setLevel(logging.DEBUG)\n",
        "\n",
        "logger.debug('test')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "regex_mail = re.compile(r'\\w+(?:\\.\\w+)*?@\\w+(?:\\.\\w+)+')\n",
        "# modified from https://stackoverflow.com/a/163684/5587393\n",
        "regex_link = re.compile(r'(?:\\b(?:(?:https?|ftp|file)://|www))[-A-Za-z0-9+&@#/%?=~_|!:,.;]+[-A-Za-z0-9+&@#%=~_|]')\n",
        "# in a sentence there must be at least 4 words of length 2 each\n",
        "regex_at_least_4_words_in_sentence = re.compile(r\"^(?=.*?(?:[,:;()]?[a-zA-Z']{2,}[,:;()]?(?: |$)[^a-zA-Z]*?){4,})\")\n",
        "# a string like \"first.Second\" could be misinterpreted by the tokenizer as a single token\n",
        "# with the regex it becomes \"first. Second\"\n",
        "regex_distance_between_period_and_following_word = re.compile(r'\\.(?!\\s|$)')\n",
        "# compress consecutive whitespaces\n",
        "regex_multiple_spaces = re.compile(r'\\s{2,}')\n",
        "# interrupted words usually have a \"- \" at the end before the new line, 'inter- rupted' -> 'interrupted'\n",
        "# NOTE: must be after whitespace compression\n",
        "regex_interrupted_word = re.compile(r'([a-zA-Z])- ')\n",
        "# remove page numbers, that are usually enclosed in characters like = or -, for example \"-12-\"\n",
        "regex_consecutive_meaningless_chars = re.compile(r'[^\\.a-zA-Z0-9\\s()]{2,} *(?:\\d+)?|(?P<prepage>[^a-zA-Z\\s\\d\\.])\\d+(?P=prepage)')\n",
        "# remove paragraphs id, '1.2.3' -> ''\n",
        "regex_dot_separated_digits = re.compile(r'(?:\\d+\\.)+\\d+')\n",
        "# remove meaningless chars after sentence start, '. (- start' -> '. start'\n",
        "regex_clean_start = re.compile(r'\\.(\\s?)[^a-zA-Z\\s]+')\n",
        "# recover missing apices\n",
        "regex_missing_apices = re.compile(r\"\\b(can|doesn|couldn|won|wouldn) t\\b\")\n",
        "\n",
        "def clean_from_short_sentences(text: str) -> str:\n",
        "    return '.'.join(sentence for sentence in text.split('.') if regex_at_least_4_words_in_sentence.match(sentence) is not None)\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    for clean_function in [lambda x: regex_mail.sub('', x),\n",
        "                           lambda x: regex_link.sub('', x),\n",
        "                           lambda x: regex_dot_separated_digits.sub('', x),\n",
        "                           lambda x: regex_consecutive_meaningless_chars.sub('', x),\n",
        "                           lambda x: regex_clean_start.sub(r'.\\1', x),\n",
        "                           # everything that is remove should be placed before this line so that \n",
        "                           # eventual spaces are compressed with regex_multiple_space\n",
        "                           lambda x: regex_multiple_spaces.sub(' ', x),\n",
        "                           lambda x: regex_interrupted_word.sub(r'\\1', x),\n",
        "                           lambda x: regex_missing_apices.sub(r\"\\1't\", x),\n",
        "                           lambda x: clean_from_short_sentences(x),\n",
        "                           lambda x: regex_distance_between_period_and_following_word.sub('. ', x)]:\n",
        "        text = clean_function(text)\n",
        "    return text\n",
        "\n",
        "test_text = 'this is a test (me@gmail.it) -12- that wi-  ll be   cleaned. with 2 5 6 not valid. two sentences can t be good enough http://or.not.'\n",
        "cleaned_text = clean_text(test_text)\n",
        "print(cleaned_text)\n",
        "assert cleaned_text == 'this is a test () that will be cleaned. two sentences can\\'t be good enough '"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBHkUGAsukWJ",
        "outputId": "0eba9817-216a-4e6c-a78c-021aadd27b07"
      },
      "id": "bBHkUGAsukWJ",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is a test () that will be cleaned. two sentences can't be good enough \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "def remove_columns_prefix(df: pd.DataFrame) -> None:\n",
        "    '''remove prefix 'info.' from the columns of df'''\n",
        "    df.rename(columns=lambda c: c.rsplit('.', 1)[-1], inplace=True)\n",
        "\n",
        "def get_df_with_docs(file_path: str, nrows=None, skiprows=1) -> pd.DataFrame:\n",
        "    ''' get a dataframe containing nrows and skipping the first `skiprows` (including the header)'''\n",
        "    df_dataset = pd.read_csv(file_path, converters={ 'info.family': ast.literal_eval }, \n",
        "                             nrows=nrows, skiprows=range(1, skiprows))\n",
        "    remove_columns_prefix(df_dataset)\n",
        "    return df_dataset\n",
        "\n",
        "def get_document_by_line(file_path: str, line: int) -> str:\n",
        "    ''' the line includes the header too '''\n",
        "    # range from 1 is used to keep the first row https://stackoverflow.com/a/27325729/5587393\n",
        "    df = get_df_with_docs(file_path, 1, line - 1)\n",
        "    return df['rulebook'].iloc[0]\n",
        "\n",
        "def get_document_by_id(file_path: str, id: int) -> str:\n",
        "     with pd.read_csv(file_path, chunksize=1, converters={ 'family': ast.literal_eval }) as reader:\n",
        "        while True:\n",
        "            df = next(reader)\n",
        "            bg_id = df['info.id'].iloc[0]\n",
        "            if bg_id == id:\n",
        "                return df['rulebook'].iloc[0]\n",
        "\n",
        "assert get_document_by_id(DATASET_FILE_PATH, 2310) == get_document_by_line(DATASET_FILE_PATH, 40)"
      ],
      "metadata": {
        "id": "VepMko8FPiyw"
      },
      "id": "VepMko8FPiyw",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "361b1290-00e4-42f3-85a4-badadb8d574f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "361b1290-00e4-42f3-85a4-badadb8d574f",
        "outputId": "3b4aaf49-7de6-4d5c-a61a-1973bddc2f64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0], [1, 1, 2], [2, 3]]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from typing import Tuple\n",
        "\n",
        "def get_sentences_from_clusters(clusters: List[List[Tuple[int, int]]], sentences: List[Sentence]) -> List[List[int]]:\n",
        "    # + sentences[0] because sentences are built from the entire text and not from the current group\n",
        "    clusters_on_sentences = [[next(filter(lambda x: x[1].does_include_pos(entity[0] + sentences[0].start), enumerate(sentences)))[0] \n",
        "                              for entity in cluster]\n",
        "                             for cluster in clusters]\n",
        "\n",
        "    return clusters_on_sentences\n",
        "\n",
        "# text = 'Alice goes down the rabbit hole. Where she would discover a new reality beyond her expectations.'\n",
        "# sentences = get_sentences_from_text(text)\n",
        "# clusters = [[(0, 5), (39, 42), (79, 82)]]\n",
        "sentences = [Sentence(content=' A boom unit is destroyed when it has received 5 floatation hits,  and is removed from play, clearing the hex for unobstructed vessel  movement', start=65348, end=65490), \n",
        "             Sentence(content=' If a boom unit destroyed on the same game turn it is attacked, the  attacking vessel (A', start=65492, end=65579), \n",
        "             Sentence(content=' is not subject to a die roll on the Vessel  Fouling Table (Combat Table No', start=65581, end=65655), \n",
        "             Sentence(content=' 13) and continues its movement', start=65657, end=65687)]\n",
        "clusters = [[(8, 11), (31, 32)], [(192, 193), (231, 232), (308, 308)], [(306, 307), (328, 330)]]        \n",
        "get_sentences_from_clusters(clusters, sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e53dc33-31ba-4e04-80e6-dc645714fe60",
      "metadata": {
        "id": "2e53dc33-31ba-4e04-80e6-dc645714fe60"
      },
      "outputs": [],
      "source": [
        "from typing import List, Set\n",
        "from itertools import groupby\n",
        "from operator import itemgetter\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse.csgraph import connected_components\n",
        "\n",
        "def get_rule_groups_from_sentence_clusters(sentences: List[Sentence], sentence_clusters: List[List[int]]) -> List[List[int]]:\n",
        "    def normalize_group(group: Set[int]) -> List[List[int]]:\n",
        "        '''each group could contain multiple consecutive sublists. this method split these sublists'''\n",
        "        res = []\n",
        "\n",
        "        # https://stackoverflow.com/a/23861347/5587393\n",
        "        for k, g in groupby(enumerate(sorted(list(group))), lambda x: x[0] - x[1]):\n",
        "            res.append(list(map(itemgetter(1), g)))\n",
        "\n",
        "        return res\n",
        "    # the graph is built as a directed sparse graph where the first element of each cluster\n",
        "    # is connected to the other elements in the same cluster\n",
        "    graph = [[0 for _ in range(len(sentences))] for __ in range(len(sentences))]\n",
        "    for cluster in sentence_clusters:\n",
        "        for sentence in cluster[1:]:\n",
        "            graph[cluster[0]][sentence] = 1\n",
        "\n",
        "    # find the connected components of the graph created from the clusters returned after coref     \n",
        "    graph = csr_matrix(graph)\n",
        "    n_components, labels = connected_components(csgraph=graph, directed=False, return_labels=True)\n",
        "    groups = [set() for _ in range(n_components)]\n",
        "    for i, label in enumerate(labels):\n",
        "        groups[label].add(i)\n",
        "\n",
        "    return [norm_group for group in groups for norm_group in normalize_group(group)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c83a628-762c-4084-8d9c-4b64a615fe09",
      "metadata": {
        "id": "4c83a628-762c-4084-8d9c-4b64a615fe09",
        "outputId": "962e7295-8f45-4dc0-80dc-8714bf5510e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(9, 10), (31, 33), (41, 45), (69, 70), (76, 78)],\n",
              " [(35, 38), (65, 66)],\n",
              " [(69, 70), (93, 96), (116, 119), (148, 151)],\n",
              " [(134, 138), (163, 169)]]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from typing import List, Tuple\n",
        "def convert_result_to_cluster(result, pipeline) -> List[List[Tuple[int, int]]]:\n",
        "    component_names = [x[0] for x in pipeline]\n",
        "    if 'coreferee' in component_names:\n",
        "        return [[(result[entity[0]].idx, result[entity[0]].idx + len(result[entity[0]]) - 1) \n",
        "                 for entity in chain] for chain in result._.coref_chains]\n",
        "    elif 'fastcoref' in component_names:\n",
        "        return result._.coref_clusters\n",
        "\n",
        "result = nlp(\"Although he was very busy with his work, Peter had had enough of it. He and his wife decided they needed a holiday. They travelled to Spain because they loved the country very much.\")\n",
        "convert_result_to_cluster(result, nlp.pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FWKfCPyrdjis",
      "metadata": {
        "id": "FWKfCPyrdjis"
      },
      "outputs": [],
      "source": [
        "from typing import List, Tuple\n",
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "def get_rules(text: str) -> List[str]:\n",
        "    text = clean_text(text)\n",
        "    sentences = get_sentences_from_text(text)\n",
        "    \n",
        "    GROUP_STEP_OFFSET = 2\n",
        "    # I create groups of 4 sentences to speed up the process of finding connected sentences\n",
        "    # and to make sure to find connected sentences not immediately adjacent\n",
        "    sentences_groups = [sentences[i:min(i+4, len(sentences))] for i in range(0, len(sentences) - 2, GROUP_STEP_OFFSET)]\n",
        "    doc_groups = nlp.pipe(['.'.join(map(lambda s: s.content, group)) for group in sentences_groups])\n",
        "\n",
        "    cluster_groups = []\n",
        "    for i, group in enumerate(sentences_groups):\n",
        "        group_text = next(doc_groups)\n",
        "        group_coref_clusters = convert_result_to_cluster(group_text, nlp.pipeline)\n",
        "        group_sentence_clusters = get_sentences_from_clusters(group_coref_clusters, group)\n",
        "        # + i * GROUP_STEP_OFFSET to retrieve the actual index of the sentence\n",
        "        cluster_groups.extend([sentence_id + i * GROUP_STEP_OFFSET for sentence_id in gsc] \n",
        "                               for gsc in group_sentence_clusters)\n",
        "        \n",
        "    rule_groups = get_rule_groups_from_sentence_clusters(sentences, cluster_groups)                                                                                \n",
        "    \n",
        "    return ['. '.join([sentences[s_index].content for s_index in group]) for group in rule_groups]\n",
        "\n",
        "text = get_document_by_id(DATASET_FILE_PATH, 24770)\n",
        "rules = get_rules(text)\n",
        "\n",
        "rules"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "from collections import Counter, defaultdict\n",
        "from typing import List, Dict\n",
        "\n",
        "def filter_tokens_as_components(doc: spacy.tokens.Doc) -> Dict[str, List[spacy.tokens.Token]]:\n",
        "    tokens_dict = defaultdict(list)\n",
        "\n",
        "    for token in doc:\n",
        "        if len(token) >= 3 and \\\n",
        "            token.pos_ in ['NOUN', 'PROPN'] and \\\n",
        "            token.dep_ in ['nsubj', 'dobj', 'nsubjpass', 'pobj', 'compound']:\n",
        "            tokens_dict[token.lemma_.lower()].append(token)\n",
        "           \n",
        "    return tokens_dict\n",
        "\n",
        "def find_n_most_common_nouns(n, docs: List[spacy.tokens.Doc]) -> List[str]:\n",
        "    docs_sets = [set(filter_tokens_as_components(doc).keys())\n",
        "                 for doc in docs]\n",
        "    all_tokens_from_docs = itertools.chain(*docs_sets)\n",
        "    tokens_counter = Counter(all_tokens_from_docs)\n",
        "    return tokens_counter.most_common(n)\n",
        "    \n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "df_dataset = get_df_with_docs(DATASET_FILE_PATH, 10, 50)\n",
        "docs = nlp.pipe(map(clean_text, df_dataset['rulebook'].values))\n",
        "\n",
        "find_n_most_common_nouns(10, docs)"
      ],
      "metadata": {
        "id": "w-JVFrfg4BwA"
      },
      "id": "w-JVFrfg4BwA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "from collections import namedtuple\n",
        "from spacy.matcher import Matcher, DependencyMatcher\n",
        "\n",
        "LuckMetrics = namedtuple('LuckMetrics', ['dice_based', 'drawing_based', 'shuffling_based', 'random_based'])\n",
        "\n",
        "def get_luck_metrics(doc: spacy.tokens.Doc) -> LuckMetrics:\n",
        "    # ---------- random ----------\n",
        "    random_matcher = Matcher(doc.vocab)\n",
        "    random_patterns_match = [\n",
        "        [{\"LEMMA\": { \"IN\": [\"random\", \"randomly\"]}}]\n",
        "    ]\n",
        "    random_matcher.add(\"random\", random_patterns_match)\n",
        "\n",
        "    # ---------- shuffle ----------\n",
        "    shuffle_matcher = Matcher(doc.vocab)\n",
        "    shuffle_patterns_match = [\n",
        "        [{\"LEMMA\": \"shuffle\", \"POS\": \"VERB\"}]\n",
        "    ]\n",
        "    shuffle_matcher.add(\"shuffle\", shuffle_patterns_match)\n",
        "\n",
        "    # ---------- card drawing ----------\n",
        "    drawing_matcher = DependencyMatcher(doc.vocab)    \n",
        "    drawing_patterns = [\n",
        "        [\n",
        "            {\n",
        "                \"RIGHT_ID\": \"drawing\",\n",
        "                \"RIGHT_ATTRS\": {\"LEMMA\": \"draw\", \"POS\": \"VERB\"}\n",
        "            },\n",
        "            {\n",
        "                \"LEFT_ID\": \"drawing\",\n",
        "                \"REL_OP\": \">\",\n",
        "                \"RIGHT_ID\": \"card\",\n",
        "                \"RIGHT_ATTRS\": {\n",
        "                    \"LEMMA\": \"card\",\n",
        "                    \"POS\": \"NOUN\", \n",
        "                    \"DEP\": { \"IN\": ['dobj', 'nsubjpass', 'compound'] }\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "    ]\n",
        "    drawing_matcher.add(\"drawing\", drawing_patterns)\n",
        "    # ---------- dice rolling ----------\n",
        "    dice_matcher = DependencyMatcher(doc.vocab)    \n",
        "    dice_patterns = [\n",
        "        [\n",
        "            {\n",
        "                \"RIGHT_ID\": \"rolling\",\n",
        "                \"RIGHT_ATTRS\": {\"LEMMA\": { \"IN\": [\"use\", \"throw\", \"roll\"]}, \"POS\": \"VERB\"}\n",
        "            },\n",
        "            {\n",
        "                \"LEFT_ID\": \"rolling\",\n",
        "                \"REL_OP\": \">\",\n",
        "                \"RIGHT_ID\": \"dice_or_die\",\n",
        "                \"RIGHT_ATTRS\": {\n",
        "                    \"LEMMA\": { \"IN\": [\"die\", \"dice\"]},\n",
        "                    \"POS\": \"NOUN\", \n",
        "                    \"DEP\": { \"IN\": ['nsubj', 'dobj', 'nsubjpass', 'compound'] }\n",
        "                }\n",
        "            }\n",
        "        ],\n",
        "        [\n",
        "            {\n",
        "                \"RIGHT_ID\": \"rolling\",\n",
        "                \"RIGHT_ATTRS\": {\"LEMMA\": { \"IN\": [\"use\", \"throw\", \"roll\"]}, \"POS\": \"VERB\"}\n",
        "            },\n",
        "            {\n",
        "                \"LEFT_ID\": \"rolling\",\n",
        "                \"REL_OP\": \">\",\n",
        "                \"RIGHT_ID\": \"number\",\n",
        "                \"RIGHT_ATTRS\": {\n",
        "                    \"IS_DIGIT\": True, \n",
        "                    \"DEP\": { \"IN\": ['dobj'] }\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "    ]\n",
        "    dice_matcher.add(\"diceroll\", dice_patterns)\n",
        "\n",
        "    dice_matches = dice_matcher(doc) \n",
        "    draw_matches = drawing_matcher(doc)\n",
        "    shuffle_matches = shuffle_matcher(doc)\n",
        "    random_matches = random_matcher(doc)\n",
        "\n",
        "    # TODO: needs normalization? (divide by rulebook length or tokens)\n",
        "\n",
        "    return LuckMetrics(len(dice_matches), len(draw_matches), len(shuffle_matches), len(random_matches))\n",
        "\n",
        "text = get_document_by_line(DATASET_FILE_PATH, 130)\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(clean_text(text))\n",
        "print(len(doc), len(doc.text))\n",
        "print(get_luck_metrics(doc))\n",
        "\n",
        "# displacy.render(doc, style='dep', jupyter=True)"
      ],
      "metadata": {
        "id": "Ayy4X1vaYYCj",
        "outputId": "f8fbf277-a792-4271-c5bb-b85682d9c16f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Ayy4X1vaYYCj",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2603 12372\n",
            "LuckMetrics(dice_based=12, drawing_based=4, shuffling_based=3, random_based=0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''you can only take this because it can be outrageous. \n",
        "    you can't take it. you could not also choose. you may never be sure of the result. \n",
        "    you can decide the next thing. he has no other choice but to stop, another option is winning.'''\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(clean_text(text))\n",
        "print([token.lemma_ for token in doc])\n",
        "print(len(doc), len(doc.text))\n",
        "\n",
        "displacy.render(doc, style='dep', jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "I3JtzI3p9lvj",
        "outputId": "43a806d7-f449-4fcf-d12a-2b8f08bd8222"
      },
      "id": "I3JtzI3p9lvj",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['you', 'can', 'only', 'take', 'this', 'because', 'it', 'can', 'be', 'outrageous', '.', 'you', 'can', 'not', 'take', 'it', '.', 'you', 'could', 'not', 'also', 'choose', '.', 'you', 'may', 'never', 'be', 'sure', 'of', 'the', 'result', '.', 'you', 'can', 'decide', 'the', 'next', 'thing', '.', 'he', 'have', 'no', 'other', 'choice', 'but', 'to', 'stop', ',', 'another', 'option', 'be', 'win']\n",
            "52 228\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"8b77e7c5d1ac44649eb5a83a68f7564f-0\" class=\"displacy\" width=\"8100\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">you</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">can</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">only</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">take</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">this</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">because</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">SCONJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">it</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">can</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">be</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">outrageous.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">you</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">ca</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">n't</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">PART</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">take</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">it.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">you</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">could</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">not</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">PART</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">also</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3375\">choose.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3375\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3550\">you</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3550\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3725\">may</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3725\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3900\">never</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3900\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4075\">be</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4075\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4250\">sure</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4250\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4425\">of</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4425\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4600\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4600\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4775\">result.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4775\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4950\">you</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4950\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5125\">can</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5125\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5300\">decide</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5300\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5475\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5475\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5650\">next</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5650\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5825\">thing.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5825\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6000\">he</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6000\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6175\">has</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6175\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6350\">no</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6350\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6525\">other</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6525\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6700\">choice</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6700\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6875\">but</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6875\">SCONJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"7050\">to</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"7050\">PART</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"7225\">stop,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"7225\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"7400\">another</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"7400\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"7575\">option</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"7575\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"7750\">is</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"7750\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"7925\">winning</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"7925\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,89.5 570.0,89.5 570.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,177.0 565.0,177.0 565.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,354.0 L237,342.0 253,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-2\" stroke-width=\"2px\" d=\"M420,352.0 C420,264.5 560.0,264.5 560.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-3\" stroke-width=\"2px\" d=\"M595,352.0 C595,264.5 735.0,264.5 735.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M735.0,354.0 L743.0,342.0 727.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-4\" stroke-width=\"2px\" d=\"M945,352.0 C945,89.5 1445.0,89.5 1445.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M945,354.0 L937,342.0 953,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-5\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,177.0 1440.0,177.0 1440.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1120,354.0 L1112,342.0 1128,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-6\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,264.5 1435.0,264.5 1435.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1295,354.0 L1287,342.0 1303,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-7\" stroke-width=\"2px\" d=\"M595,352.0 C595,2.0 1450.0,2.0 1450.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advcl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1450.0,354.0 L1458.0,342.0 1442.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-8\" stroke-width=\"2px\" d=\"M1470,352.0 C1470,264.5 1610.0,264.5 1610.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1610.0,354.0 L1618.0,342.0 1602.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-9\" stroke-width=\"2px\" d=\"M1820,352.0 C1820,89.5 2320.0,89.5 2320.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1820,354.0 L1812,342.0 1828,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-10\" stroke-width=\"2px\" d=\"M1995,352.0 C1995,177.0 2315.0,177.0 2315.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1995,354.0 L1987,342.0 2003,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-11\" stroke-width=\"2px\" d=\"M2170,352.0 C2170,264.5 2310.0,264.5 2310.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">neg</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2170,354.0 L2162,342.0 2178,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-12\" stroke-width=\"2px\" d=\"M2345,352.0 C2345,264.5 2485.0,264.5 2485.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2485.0,354.0 L2493.0,342.0 2477.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-13\" stroke-width=\"2px\" d=\"M2695,352.0 C2695,2.0 3375.0,2.0 3375.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2695,354.0 L2687,342.0 2703,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-14\" stroke-width=\"2px\" d=\"M2870,352.0 C2870,89.5 3370.0,89.5 3370.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2870,354.0 L2862,342.0 2878,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-15\" stroke-width=\"2px\" d=\"M3045,352.0 C3045,177.0 3365.0,177.0 3365.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">neg</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3045,354.0 L3037,342.0 3053,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-16\" stroke-width=\"2px\" d=\"M3220,352.0 C3220,264.5 3360.0,264.5 3360.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3220,354.0 L3212,342.0 3228,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-17\" stroke-width=\"2px\" d=\"M3570,352.0 C3570,89.5 4070.0,89.5 4070.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3570,354.0 L3562,342.0 3578,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-18\" stroke-width=\"2px\" d=\"M3745,352.0 C3745,177.0 4065.0,177.0 4065.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3745,354.0 L3737,342.0 3753,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-19\" stroke-width=\"2px\" d=\"M3920,352.0 C3920,264.5 4060.0,264.5 4060.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">neg</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3920,354.0 L3912,342.0 3928,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-20\" stroke-width=\"2px\" d=\"M4095,352.0 C4095,264.5 4235.0,264.5 4235.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-20\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4235.0,354.0 L4243.0,342.0 4227.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-21\" stroke-width=\"2px\" d=\"M4270,352.0 C4270,264.5 4410.0,264.5 4410.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-21\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4410.0,354.0 L4418.0,342.0 4402.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-22\" stroke-width=\"2px\" d=\"M4620,352.0 C4620,264.5 4760.0,264.5 4760.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-22\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4620,354.0 L4612,342.0 4628,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-23\" stroke-width=\"2px\" d=\"M4445,352.0 C4445,177.0 4765.0,177.0 4765.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-23\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4765.0,354.0 L4773.0,342.0 4757.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-24\" stroke-width=\"2px\" d=\"M4970,352.0 C4970,177.0 5290.0,177.0 5290.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-24\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4970,354.0 L4962,342.0 4978,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-25\" stroke-width=\"2px\" d=\"M5145,352.0 C5145,264.5 5285.0,264.5 5285.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-25\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5145,354.0 L5137,342.0 5153,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-26\" stroke-width=\"2px\" d=\"M5495,352.0 C5495,177.0 5815.0,177.0 5815.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-26\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5495,354.0 L5487,342.0 5503,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-27\" stroke-width=\"2px\" d=\"M5670,352.0 C5670,264.5 5810.0,264.5 5810.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-27\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5670,354.0 L5662,342.0 5678,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-28\" stroke-width=\"2px\" d=\"M5320,352.0 C5320,89.5 5820.0,89.5 5820.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-28\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5820.0,354.0 L5828.0,342.0 5812.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-29\" stroke-width=\"2px\" d=\"M6020,352.0 C6020,264.5 6160.0,264.5 6160.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-29\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M6020,354.0 L6012,342.0 6028,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-30\" stroke-width=\"2px\" d=\"M6370,352.0 C6370,177.0 6690.0,177.0 6690.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-30\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M6370,354.0 L6362,342.0 6378,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-31\" stroke-width=\"2px\" d=\"M6545,352.0 C6545,264.5 6685.0,264.5 6685.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-31\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M6545,354.0 L6537,342.0 6553,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-32\" stroke-width=\"2px\" d=\"M6195,352.0 C6195,89.5 6695.0,89.5 6695.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-32\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M6695.0,354.0 L6703.0,342.0 6687.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-33\" stroke-width=\"2px\" d=\"M6720,352.0 C6720,264.5 6860.0,264.5 6860.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-33\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M6860.0,354.0 L6868.0,342.0 6852.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-34\" stroke-width=\"2px\" d=\"M7070,352.0 C7070,264.5 7210.0,264.5 7210.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-34\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M7070,354.0 L7062,342.0 7078,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-35\" stroke-width=\"2px\" d=\"M6895,352.0 C6895,177.0 7215.0,177.0 7215.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-35\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pcomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M7215.0,354.0 L7223.0,342.0 7207.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-36\" stroke-width=\"2px\" d=\"M7420,352.0 C7420,264.5 7560.0,264.5 7560.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-36\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M7420,354.0 L7412,342.0 7428,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-37\" stroke-width=\"2px\" d=\"M7595,352.0 C7595,177.0 7915.0,177.0 7915.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-37\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M7595,354.0 L7587,342.0 7603,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-38\" stroke-width=\"2px\" d=\"M7770,352.0 C7770,264.5 7910.0,264.5 7910.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-38\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M7770,354.0 L7762,342.0 7778,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-39\" stroke-width=\"2px\" d=\"M6195,352.0 C6195,2.0 7925.0,2.0 7925.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-8b77e7c5d1ac44649eb5a83a68f7564f-0-39\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M7925.0,354.0 L7933.0,342.0 7917.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "from collections import namedtuple\n",
        "from spacy.matcher import Matcher, DependencyMatcher\n",
        "\n",
        "def get_choices_amount_metric(doc: spacy.tokens.Doc) -> int:\n",
        "    # --------------  can/could/may/choose/select/... -------------- \n",
        "    # all can/could/may\n",
        "    can_could_may_matcher = Matcher(doc.vocab)\n",
        "    can_could_may_patterns = [\n",
        "        [{\n",
        "            \"LEMMA\": { \"IN\": [\"can\", \"could\", \"may\", \"decide\", \"select\", \"choose\", \"opt\"]}, \n",
        "            \"POS\": { \"IN\": [\"AUX\", \"VERB\"]}\n",
        "        }]\n",
        "    ]\n",
        "    can_could_may_matcher.add('can_could_may', can_could_may_patterns)\n",
        "    can_could_may_matches = { match[1] for match in can_could_may_matcher(doc) }\n",
        "\n",
        "    # can/could/may with only or neg\n",
        "    can_could_may_exceptions_matcher = DependencyMatcher(doc.vocab)\n",
        "    can_could_may_exceptions_patterns = [\n",
        "        [\n",
        "            #  can not/only/never verb \n",
        "            {\n",
        "                \"RIGHT_ID\": \"can_could_may\",\n",
        "                \"RIGHT_ATTRS\": {\n",
        "                    \"LEMMA\": { \"IN\": [\"can\", \"could\", \"may\"]}, \n",
        "                    \"POS\": \"AUX\"\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                \"LEFT_ID\": \"can_could_may\",\n",
        "                \"REL_OP\": \"<\",\n",
        "                \"RIGHT_ID\": \"generic_verb\",\n",
        "                \"RIGHT_ATTRS\": {\n",
        "                    \"POS\": { \"IN\": [\"AUX\", \"VERB\"] }\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                \"LEFT_ID\": \"generic_verb\",\n",
        "                \"REL_OP\": \">\",\n",
        "                \"RIGHT_ID\": \"neg_or_only\",\n",
        "                \"RIGHT_ATTRS\": {\n",
        "                    \"LEMMA\": { \"IN\": [\"not\", \"only\", \"never\"]}, \n",
        "                    \"DEP\": { \"IN\": [\"advmod\", \"neg\"] }\n",
        "                }\n",
        "            }\n",
        "        ],\n",
        "        [\n",
        "            #  not/only/never choose\n",
        "            {\n",
        "                \"RIGHT_ID\": \"decision_verb\",\n",
        "                \"RIGHT_ATTRS\": {\n",
        "                    \"LEMMA\": { \"IN\": [\"decide\", \"select\", \"choose\", \"opt\"]}, \n",
        "                    \"POS\": \"VERB\"\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                \"LEFT_ID\": \"decision_verb\",\n",
        "                \"REL_OP\": \">\",\n",
        "                \"RIGHT_ID\": \"negation\",\n",
        "                \"RIGHT_ATTRS\": {\n",
        "                    \"LEMMA\": { \"IN\": [\"not\", \"only\", \"never\"]}, \n",
        "                    \"DEP\": { \"IN\": [\"advmod\", \"neg\"] }\n",
        "                }\n",
        "            }\n",
        "        ],\n",
        "        [\n",
        "            #  can + choose are counted as 1. can token is left out\n",
        "            {\n",
        "                \"RIGHT_ID\": \"can_could_may\",\n",
        "                \"RIGHT_ATTRS\": {\n",
        "                    \"LEMMA\": { \"IN\": [\"can\", \"could\", \"may\"]}, \n",
        "                    \"POS\": \"AUX\"\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                \"LEFT_ID\": \"can_could_may\",\n",
        "                \"REL_OP\": \"<\",\n",
        "                \"RIGHT_ID\": \"decision_verb\",\n",
        "                \"RIGHT_ATTRS\": {\n",
        "                    \"LEMMA\": { \"IN\": [\"decide\", \"select\", \"choose\", \"opt\"]},\n",
        "                    \"POS\": \"VERB\"\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "    ]\n",
        "    can_could_may_exceptions_matcher.add('can_could_may_exceptions', can_could_may_exceptions_patterns)\n",
        "    can_could_may_exceptions_matches = { match[1][0] for match in can_could_may_exceptions_matcher(doc) }\n",
        "\n",
        "    # -------------- choice and option -------------- \n",
        "    choice_option_matcher = Matcher(doc.vocab)\n",
        "    choice_option_patterns = [\n",
        "        [{\n",
        "            \"LEMMA\": { \"IN\": [\"choice\", \"option\"]}, \n",
        "            \"POS\": \"NOUN\"\n",
        "        }]\n",
        "    ]\n",
        "    choice_option_matcher.add('choice_option', choice_option_patterns)\n",
        "    choice_option_matches = { match[1] for match in choice_option_matcher(doc) }\n",
        "\n",
        "    choice_option_exceptions_matcher = DependencyMatcher(doc.vocab)\n",
        "    choice_option_exceptions_patterns = [\n",
        "        [\n",
        "            {\n",
        "                \"RIGHT_ID\": \"choice\",\n",
        "                \"RIGHT_ATTRS\": {\n",
        "                    \"LEMMA\": { \"IN\": [\"choice\", \"option\"]}, \n",
        "                    \"POS\": \"NOUN\"\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                \"LEFT_ID\": \"choice\",\n",
        "                \"REL_OP\": \">\",\n",
        "                \"RIGHT_ID\": \"prefix_no\",\n",
        "                \"RIGHT_ATTRS\": {\n",
        "                    \"LEMMA\": \"no\",\n",
        "                    \"POS\": \"DET\",\n",
        "                    \"DEP\": \"det\"\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "    ]\n",
        "    choice_option_exceptions_matcher.add('choice_option_exceptions', choice_option_exceptions_patterns)\n",
        "    choice_option_exceptions_matches = { match[1][0] for match in choice_option_exceptions_matcher(doc) }\n",
        "\n",
        "    return len(can_could_may_matches.difference(can_could_may_exceptions_matches)) + \\\n",
        "           len(choice_option_matches.difference(choice_option_exceptions_matches))\n",
        "\n",
        "# text = get_document_by_line(DATASET_FILE_PATH, 130)\n",
        "text = '''you can only take this because it can be outrageous. \n",
        "    you can't take it. you can not also choose. you can never be sure of the result. \n",
        "    you can decide the next thing, or you choose the target. another choice is to win. \n",
        "    but there is no right option.'''\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(clean_text(text))\n",
        "print([(i, token.lemma_) for i, token in enumerate(doc)])\n",
        "print(len(doc), len(doc.text))\n",
        "print(get_choices_amount_metric(doc))\n",
        "\n",
        "# displacy.render(doc, style='dep', jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXvPodfk0ryj",
        "outputId": "faccb6a8-9347-440a-af8e-6a0ea1922209"
      },
      "id": "vXvPodfk0ryj",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 'you'), (1, 'can'), (2, 'only'), (3, 'take'), (4, 'this'), (5, 'because'), (6, 'it'), (7, 'can'), (8, 'be'), (9, 'outrageous'), (10, '.'), (11, 'you'), (12, 'can'), (13, 'not'), (14, 'take'), (15, 'it'), (16, '.'), (17, 'you'), (18, 'can'), (19, 'not'), (20, 'also'), (21, 'choose'), (22, '.'), (23, 'you'), (24, 'can'), (25, 'never'), (26, 'be'), (27, 'sure'), (28, 'of'), (29, 'the'), (30, 'result'), (31, '.'), (32, 'you'), (33, 'can'), (34, 'decide'), (35, 'the'), (36, 'next'), (37, 'thing'), (38, ','), (39, 'or'), (40, 'you'), (41, 'choose'), (42, 'the'), (43, 'target'), (44, '.'), (45, 'another'), (46, 'choice'), (47, 'be'), (48, 'to'), (49, 'win'), (50, '.'), (51, 'but'), (52, 'there'), (53, 'be'), (54, 'no'), (55, 'right'), (56, 'option')]\n",
            "57 245\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "import coreferee\n",
        "\n",
        "def _get_new_token_from_resolve(token: spacy.tokens.Token, \n",
        "                                chains: coreferee.data_model.ChainHolder) -> spacy.tokens.Token:\n",
        "    resolved_token = chains.resolve(token)\n",
        "    return token.text_with_ws if resolved_token is None \\\n",
        "                              else ' and '.join([res_token.text_with_ws for res_token in resolved_token])   \n",
        "\n",
        "def _process_doc_for_coref(doc: spacy.tokens.Doc) -> str:\n",
        "    replacement_tokens = []\n",
        "    chains = doc._.coref_chains\n",
        "    new_doc_tokens_text = [_get_new_token_from_resolve(token, chains) for token in doc]\n",
        "\n",
        "    return ''.join(new_doc_tokens_text)\n",
        "\n",
        "def preprocess_texts(texts: List[str]) -> List[str]:\n",
        "    nlp = spacy.load('en_core_web_trf')\n",
        "    nlp.add_pipe(\"coreferee\")\n",
        "\n",
        "    texts = [clean_text(text) for text in texts]\n",
        "    docs = nlp.pipe(texts)\n",
        "\n",
        "    return [_process_doc_for_coref(doc) for doc in docs]\n",
        "        \n",
        "# text = get_document_by_line(DATASET_FILE_PATH, 40)\n",
        "text = '''Although he was very busy with his work, the magical Peter had had enough of it. \n",
        "    He and his wife decided they needed a holiday. \n",
        "    this couple travelled to Spain because it loves the country very much.'''\n",
        "preprocess_texts([text])"
      ],
      "metadata": {
        "id": "jpT4BvSfFWTd"
      },
      "id": "jpT4BvSfFWTd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(clean_text(get_document_by_line(DATASET_FILE_PATH, 155)))\n",
        "doc.text\n",
        "# print(doc[12].dep_)\n",
        "#doc.text.find('Tinners Trail Player')"
      ],
      "metadata": {
        "id": "XojL4wsdmTqI"
      },
      "id": "XojL4wsdmTqI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "from typing import List, Set, Dict\n",
        "from rake_nltk import Rake\n",
        "from nltk.util import ngrams\n",
        "import yake\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "\n",
        "# stopwords = nlp.Defaults.stop_words\n",
        "# rake = Rake(stopwords=stopwords, punctuations={ c for c in punctuation },\n",
        "#             sentence_tokenizer=lambda txt: txt.split('.'))\n",
        "\n",
        "regex_word_within_boundaries = re.compile(r'\\b')\n",
        "MIN_TOKEN_TO_BE_CONSIDERED_COMPONENT = 4\n",
        "MAX_COMPONENTS = 100\n",
        "\n",
        "def _get_ngrams_components(doc: spacy.tokens.Doc, \\\n",
        "                           components: Dict[str, List[spacy.tokens.Token]],\n",
        "                           n_grams: int):\n",
        "    pass\n",
        "\n",
        "\n",
        "def _get_bg_components_by_deps_inspection(doc: spacy.tokens.Doc) -> Dict[str, List[int]]:\n",
        "    words_to_leave_out = ['beginning', 'board', 'book', 'case', 'clarification', 'design', \n",
        "                          'effect', 'end', 'example', 'case', 'game', 'number', \n",
        "                          'overview', 'order', 'play', 'player', 'purpose', 'reference',\n",
        "                          'result', 'rule', 'rulebook', 'section', 'set', 'setup', 'side', 'summary', \n",
        "                          'start', 'step', 'thing', 'type', 'time', 'total', 'use', 'value', 'version', 'way']\n",
        "\n",
        "    possible_components = dict(filter(lambda token: token[0] not in words_to_leave_out and \n",
        "                                      len(token[1]) >= MIN_TOKEN_TO_BE_CONSIDERED_COMPONENT, \n",
        "                                  filter_tokens_as_components(doc).items()))\n",
        "    return possible_components\n",
        "\n",
        "# def _get_lemmas_given_keywords_group(group: str, doc: spacy.tokens.Doc) -> List[str]:\n",
        "#     kw_match = re.search(r'\\b' + group + '\\\\b', doc.text)\n",
        "#     if kw_match is None:\n",
        "#         return []\n",
        "\n",
        "#     group_span = doc.char_span(kw_match.start(0), kw_match.end(0))\n",
        "#     return [token.lemma_.lower() for token in group_span]\n",
        "\n",
        "# def _get_bg_components_by_keyword_analysis(doc: spacy.tokens.Doc, max_keywords: int) -> List[str]:\n",
        "#     kw_extractor = yake.KeywordExtractor(top=max_keywords)\n",
        "#     keywords_info = kw_extractor.extract_keywords(doc.text)\n",
        "#     keyword_groups = [keyword_info[0] for keyword_info in keywords_info if keyword_info[1] < 0.1]\n",
        "\n",
        "#     return [lemma for keyword_group in keyword_groups \n",
        "#             for lemma in _get_lemmas_given_keywords_group(keyword_group, doc)]\n",
        "\n",
        "def get_bg_components(doc: spacy.tokens.Doc) -> Dict[str, List[int]]:\n",
        "    components_by_deps = _get_bg_components_by_deps_inspection(doc)\n",
        "    # print(components_by_deps)\n",
        "    # components_by_kws = _get_bg_components_by_keyword_analysis(doc, len(components_by_deps))\n",
        "    # print(components_by_kws)\n",
        "\n",
        "    # return set(components_by_deps).intersection(set(components_by_kws))\n",
        "    return components_by_deps\n",
        "\n",
        "def get_doc_variance(doc: spacy.tokens.Doc, components_dict: Dict[str, List[int]]) -> float:\n",
        "    '''variance measures how components interleave in the text. This could mean that rules involve\n",
        "    many components and are therefore more complex. variancy is computed using `np.var` on each\n",
        "    component list. the results are normalized by multiplicating for the frequency of the component.\n",
        "    eventually the partial variances are summed together and the result normalized with the \n",
        "    total numbers of tokens.'''\n",
        "    tokens_count = sum(len(token_list) for token_list in components_dict.values())\n",
        "    return sum((len(tokens) / tokens_count) * np.var([token.i for token in tokens])\n",
        "        for tokens in components_dict.values()) / len((doc))\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(clean_text(get_document_by_line(DATASET_FILE_PATH, 138)))\n",
        "print(len(doc.text))\n",
        "components = get_bg_components(doc)\n",
        "print(components)\n",
        "print(get_doc_variance(doc, components))\n",
        "\n",
        "\n",
        "# rake.extract_keywords_from_text(doc.text)\n",
        "# print(rake.get_word_frequency_distribution())\n",
        "# for keyword in rake.get_ranked_phrases_with_scores():\n",
        "#     print(keyword)\n",
        "# print(rake.get_word_degrees())"
      ],
      "metadata": {
        "id": "TKh5Jf-xovbn"
      },
      "id": "TKh5Jf-xovbn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d6596cd-3fd1-4e50-9dce-e6c333667182",
      "metadata": {
        "id": "7d6596cd-3fd1-4e50-9dce-e6c333667182"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple\n",
        "import pandas as pd\n",
        "import ast\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def get_rules_features(id: int, doc: spacy.tokens.Doc) -> Tuple[int, float]:\n",
        "    logger.info(f'processing board game {id}')\n",
        "    rulebook_len = len(doc)\n",
        "    bg_components = get_bg_components(doc)\n",
        "    print(bg_components)\n",
        "\n",
        "    return 0, 0\n",
        "    # rules = get_rules(text)\n",
        "    # rule_count = len(rules)\n",
        "    # return rule_count, len(text) / rule_count\n",
        "\n",
        "def apply_for_rulebook_features(row, docs_dict):\n",
        "    next_doc_info = next(docs_dict)\n",
        "    assert next_doc_info[0] == row.id\n",
        "    return pd.Series(get_rules_features(row.id, next_doc_info[1]), \n",
        "                     index=['rule_count', 'avg_rule_len'])\n",
        "\n",
        "PROCESSED_DATASET_FILE_PATH = 'data/processed_dataset.csv' if WORKING_LOCALLY \\\n",
        "    else '/content/drive/My Drive/Projects/IRBoardGameComplexity/processed_dataset.csv'\n",
        "\n",
        "# ast.literal_eval converts the family column string into a python array\n",
        "# with pd.read_csv(DATASET_FILE_PATH, chunksize=5, converters={ 'info.family': ast.literal_eval }) as reader:\n",
        "#     for df in reader:\n",
        "df_dataset = pd.read_csv(DATASET_FILE_PATH, converters={ 'info.family': ast.literal_eval }, nrows=1)\n",
        "remove_columns_prefix(df_dataset)\n",
        "docs_dict = zip(df_dataset['id'].values, \n",
        "                nlp.pipe(map(clean_text, df_dataset['rulebook'].values)))\n",
        "\n",
        "df_rules_features = df_dataset.apply(lambda x: apply_for_rulebook_features(x, docs_dict),\n",
        "                                     axis='columns')\n",
        "df_features = df_dataset[['averageweight', 'playingtime', 'family']].join(df_rules_features)\n",
        "        \n",
        "# one-hot encoding \"family\" field \n",
        "# from https://stackoverflow.com/questions/71401193/one-hot-encoding-in-python-for-array-values-in-a-dataframe\n",
        "df_features = df_features.join(df_features.pop('family').apply('|'.join).str.get_dummies())\n",
        "df_features.head()\n",
        "\n",
        "# df_features.to_csv(PROCESSED_DATASET_FILE_PATH, header=True, index=False, mode='w')    \n",
        "# if not WORKING_LOCALLY:\n",
        "#     drive.flush_and_unmount()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marco-luzzara/boardgame-complexity-predictor/blob/master/src/extract_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "gOE9-ZKtwDuH",
      "metadata": {
        "id": "gOE9-ZKtwDuH"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "import os\n",
        "WORKING_LOCALLY = bool(os.getenv('WORKING_LOCALLY'))\n",
        "\n",
        "if WORKING_LOCALLY:\n",
        "    DATASET_FILE_PATH = 'data/dataset.csv'\n",
        "else:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    DATASET_FILE_PATH = '/content/drive/My Drive/Projects/IRBoardGameComplexity/dataset.csv'\n",
        "    !pip install spacy-transformers\n",
        "    !python3 -m pip install coreferee==1.3.*\n",
        "    !python3 -m coreferee install en\n",
        "    !python -m spacy download en_core_web_lg\n",
        "    !python -m spacy download en_core_web_trf\n",
        "    !pip install git+https://github.com/LIAAD/yake\n",
        "    !pip install rake-nltk\n",
        "    clear_output(wait=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3aa4a086-aa20-4def-b17a-3b4ff4fad93f",
      "metadata": {
        "id": "3aa4a086-aa20-4def-b17a-3b4ff4fad93f"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "## +++++++++++ with fastcoref\n",
        "# from fastcoref import spacy_component\n",
        "# nlp = spacy.load(\"en_core_web_sm\", exclude=[\"parser\", \"lemmatizer\", \"ner\", \"textcat\"])\n",
        "# nlp.add_pipe(\"fastcoref\")\n",
        "#              #config={'model_architecture': 'LingMessCoref', 'model_path': 'biu-nlp/lingmess-coref'})\n",
        "\n",
        "# # to remove tqdm progress bar: https://stackoverflow.com/questions/37091673/silence-tqdms-output-while-running-tests-or-running-the-code-via-cron\n",
        "# from tqdm.auto import tqdm\n",
        "# from functools import partialmethod\n",
        "# tqdm.__init__ = partialmethod(tqdm.__init__, disable=True, ncols=0, nrows=0, gui=False, bar_format='', leave=False)\n",
        "\n",
        "## +++++++++++ with coreferee\n",
        "import coreferee\n",
        "nlp = spacy.load('en_core_web_trf')\n",
        "nlp.add_pipe(\"coreferee\")\n",
        "\n",
        "clear_output(wait=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a4bcea26-c1a3-45fb-845e-98cae3073e85",
      "metadata": {
        "id": "a4bcea26-c1a3-45fb-845e-98cae3073e85",
        "outputId": "3f55614b-9191-497d-fe9c-301c81832d14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-11-22 08:30:37,499 bgg_predict  DEBUG    test\n",
            "DEBUG:bgg_predict:test\n"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "\n",
        "logger = logging.getLogger('bgg_predict')\n",
        "logger.handlers.clear()\n",
        "handler = logging.StreamHandler()\n",
        "formatter = logging.Formatter(\n",
        "        '%(asctime)s %(name)-12s %(levelname)-8s %(message)s')\n",
        "handler.setFormatter(formatter)\n",
        "logger.addHandler(handler)\n",
        "logger.setLevel(logging.DEBUG)\n",
        "\n",
        "logger.debug('test')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "regex_mail = re.compile(r'\\w+(?:\\.\\w+)*?@\\w+(?:\\.\\w+)+')\n",
        "# modified from https://stackoverflow.com/a/163684/5587393\n",
        "regex_link = re.compile(r'(?:\\b(?:(?:https?|ftp|file)://|www))[-A-Za-z0-9+&@#/%?=~_|!:,.;]+[-A-Za-z0-9+&@#%=~_|]')\n",
        "# in a sentence there must be at least 4 words of length 2 each\n",
        "regex_at_least_4_words_in_sentence = re.compile(r\"^(?=.*?(?:[,:;()]?[a-zA-Z']{2,}[,:;()]?(?: |$)[^a-zA-Z]*?){4,})\")\n",
        "# a string like \"first.Second\" could be misinterpreted by the tokenizer as a single token\n",
        "# with the regex it becomes \"first. Second\"\n",
        "regex_distance_between_period_and_following_word = re.compile(r'\\.(?!\\s|$)')\n",
        "# compress consecutive whitespaces\n",
        "regex_multiple_spaces = re.compile(r'\\s{2,}')\n",
        "# interrupted words usually have a \"- \" at the end before the new line, 'inter- rupted' -> 'interrupted'\n",
        "# NOTE: must be after whitespace compression\n",
        "regex_interrupted_word = re.compile(r'([a-zA-Z])- ')\n",
        "# remove page numbers, that are usually enclosed in characters like = or -, for example \"-12-\"\n",
        "regex_consecutive_meaningless_chars = re.compile(r'[^\\.a-zA-Z0-9\\s()]{2,} *(?:\\d+)?|(?P<prepage>[^a-zA-Z\\s\\d\\.])\\d+(?P=prepage)')\n",
        "# remove paragraphs id, '1.2.3' -> ''\n",
        "regex_dot_separated_digits = re.compile(r'(?:\\d+\\.)+\\d+')\n",
        "# remove meaningless chars after sentence start, '. (- start' -> '. start'\n",
        "regex_clean_start = re.compile(r'\\.(\\s?)[^a-zA-Z\\s]+')\n",
        "# recover missing apices\n",
        "regex_missing_apices = re.compile(r\"\\b(can|doesn|couldn|won|wouldn) t\\b\")\n",
        "\n",
        "def clean_from_short_sentences(text: str) -> str:\n",
        "    return '.'.join(sentence for sentence in text.split('.') if regex_at_least_4_words_in_sentence.match(sentence) is not None)\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    for clean_function in [lambda x: regex_mail.sub('', x),\n",
        "                           lambda x: regex_link.sub('', x),\n",
        "                           lambda x: regex_dot_separated_digits.sub('', x),\n",
        "                           lambda x: regex_consecutive_meaningless_chars.sub('', x),\n",
        "                           lambda x: regex_clean_start.sub(r'.\\1', x),\n",
        "                           # everything that is remove should be placed before this line so that \n",
        "                           # eventual spaces are compressed with regex_multiple_space\n",
        "                           lambda x: regex_multiple_spaces.sub(' ', x),\n",
        "                           lambda x: regex_interrupted_word.sub(r'\\1', x),\n",
        "                           lambda x: regex_missing_apices.sub(r\"\\1't\", x),\n",
        "                           lambda x: clean_from_short_sentences(x),\n",
        "                           lambda x: regex_distance_between_period_and_following_word.sub('. ', x)]:\n",
        "        text = clean_function(text)\n",
        "    return text\n",
        "\n",
        "test_text = 'this is a test (me@gmail.it) -12- that wi-  ll be   cleaned. with 2 5 6 not valid. two sentences can t be good enough http://or.not.'\n",
        "cleaned_text = clean_text(test_text)\n",
        "print(cleaned_text)\n",
        "assert cleaned_text == 'this is a test () that will be cleaned. two sentences can\\'t be good enough '"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBHkUGAsukWJ",
        "outputId": "5d01a03c-0be0-465e-ce32-2aff00390e15"
      },
      "id": "bBHkUGAsukWJ",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is a test () that will be cleaned. two sentences can't be good enough \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "def remove_columns_prefix(df: pd.DataFrame) -> None:\n",
        "    '''remove prefix 'info.' from the columns of df'''\n",
        "    df.rename(columns=lambda c: c.rsplit('.', 1)[-1], inplace=True)\n",
        "\n",
        "def get_df_with_docs(file_path: str, nrows=None, skiprows=1) -> pd.DataFrame:\n",
        "    ''' get a dataframe containing nrows and skipping the first `skiprows` (including the header)'''\n",
        "    df_dataset = pd.read_csv(file_path, converters={ 'info.family': ast.literal_eval }, \n",
        "                             nrows=nrows, skiprows=range(1, skiprows))\n",
        "    remove_columns_prefix(df_dataset)\n",
        "    return df_dataset\n",
        "\n",
        "def get_document_by_line(file_path: str, line: int) -> str:\n",
        "    ''' the line includes the header too '''\n",
        "    # range from 1 is used to keep the first row https://stackoverflow.com/a/27325729/5587393\n",
        "    df = get_df_with_docs(file_path, 1, line - 1)\n",
        "    return df['rulebook'].iloc[0]\n",
        "\n",
        "def get_document_by_id(file_path: str, id: int) -> str:\n",
        "     with pd.read_csv(file_path, chunksize=1, converters={ 'family': ast.literal_eval }) as reader:\n",
        "        while True:\n",
        "            df = next(reader)\n",
        "            bg_id = df['info.id'].iloc[0]\n",
        "            if bg_id == id:\n",
        "                return df['rulebook'].iloc[0]\n",
        "\n",
        "assert get_document_by_id(DATASET_FILE_PATH, 2310) == get_document_by_line(DATASET_FILE_PATH, 40)"
      ],
      "metadata": {
        "id": "VepMko8FPiyw"
      },
      "id": "VepMko8FPiyw",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "361b1290-00e4-42f3-85a4-badadb8d574f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "361b1290-00e4-42f3-85a4-badadb8d574f",
        "outputId": "3b4aaf49-7de6-4d5c-a61a-1973bddc2f64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0], [1, 1, 2], [2, 3]]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from typing import Tuple\n",
        "\n",
        "def get_sentences_from_clusters(clusters: List[List[Tuple[int, int]]], sentences: List[Sentence]) -> List[List[int]]:\n",
        "    # + sentences[0] because sentences are built from the entire text and not from the current group\n",
        "    clusters_on_sentences = [[next(filter(lambda x: x[1].does_include_pos(entity[0] + sentences[0].start), enumerate(sentences)))[0] \n",
        "                              for entity in cluster]\n",
        "                             for cluster in clusters]\n",
        "\n",
        "    return clusters_on_sentences\n",
        "\n",
        "# text = 'Alice goes down the rabbit hole. Where she would discover a new reality beyond her expectations.'\n",
        "# sentences = get_sentences_from_text(text)\n",
        "# clusters = [[(0, 5), (39, 42), (79, 82)]]\n",
        "sentences = [Sentence(content=' A boom unit is destroyed when it has received 5 floatation hits,  and is removed from play, clearing the hex for unobstructed vessel  movement', start=65348, end=65490), \n",
        "             Sentence(content=' If a boom unit destroyed on the same game turn it is attacked, the  attacking vessel (A', start=65492, end=65579), \n",
        "             Sentence(content=' is not subject to a die roll on the Vessel  Fouling Table (Combat Table No', start=65581, end=65655), \n",
        "             Sentence(content=' 13) and continues its movement', start=65657, end=65687)]\n",
        "clusters = [[(8, 11), (31, 32)], [(192, 193), (231, 232), (308, 308)], [(306, 307), (328, 330)]]        \n",
        "get_sentences_from_clusters(clusters, sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e53dc33-31ba-4e04-80e6-dc645714fe60",
      "metadata": {
        "id": "2e53dc33-31ba-4e04-80e6-dc645714fe60"
      },
      "outputs": [],
      "source": [
        "from typing import List, Set\n",
        "from itertools import groupby\n",
        "from operator import itemgetter\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse.csgraph import connected_components\n",
        "\n",
        "def get_rule_groups_from_sentence_clusters(sentences: List[Sentence], sentence_clusters: List[List[int]]) -> List[List[int]]:\n",
        "    def normalize_group(group: Set[int]) -> List[List[int]]:\n",
        "        '''each group could contain multiple consecutive sublists. this method split these sublists'''\n",
        "        res = []\n",
        "\n",
        "        # https://stackoverflow.com/a/23861347/5587393\n",
        "        for k, g in groupby(enumerate(sorted(list(group))), lambda x: x[0] - x[1]):\n",
        "            res.append(list(map(itemgetter(1), g)))\n",
        "\n",
        "        return res\n",
        "    # the graph is built as a directed sparse graph where the first element of each cluster\n",
        "    # is connected to the other elements in the same cluster\n",
        "    graph = [[0 for _ in range(len(sentences))] for __ in range(len(sentences))]\n",
        "    for cluster in sentence_clusters:\n",
        "        for sentence in cluster[1:]:\n",
        "            graph[cluster[0]][sentence] = 1\n",
        "\n",
        "    # find the connected components of the graph created from the clusters returned after coref     \n",
        "    graph = csr_matrix(graph)\n",
        "    n_components, labels = connected_components(csgraph=graph, directed=False, return_labels=True)\n",
        "    groups = [set() for _ in range(n_components)]\n",
        "    for i, label in enumerate(labels):\n",
        "        groups[label].add(i)\n",
        "\n",
        "    return [norm_group for group in groups for norm_group in normalize_group(group)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c83a628-762c-4084-8d9c-4b64a615fe09",
      "metadata": {
        "id": "4c83a628-762c-4084-8d9c-4b64a615fe09",
        "outputId": "962e7295-8f45-4dc0-80dc-8714bf5510e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(9, 10), (31, 33), (41, 45), (69, 70), (76, 78)],\n",
              " [(35, 38), (65, 66)],\n",
              " [(69, 70), (93, 96), (116, 119), (148, 151)],\n",
              " [(134, 138), (163, 169)]]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from typing import List, Tuple\n",
        "def convert_result_to_cluster(result, pipeline) -> List[List[Tuple[int, int]]]:\n",
        "    component_names = [x[0] for x in pipeline]\n",
        "    if 'coreferee' in component_names:\n",
        "        return [[(result[entity[0]].idx, result[entity[0]].idx + len(result[entity[0]]) - 1) \n",
        "                 for entity in chain] for chain in result._.coref_chains]\n",
        "    elif 'fastcoref' in component_names:\n",
        "        return result._.coref_clusters\n",
        "\n",
        "result = nlp(\"Although he was very busy with his work, Peter had had enough of it. He and his wife decided they needed a holiday. They travelled to Spain because they loved the country very much.\")\n",
        "convert_result_to_cluster(result, nlp.pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FWKfCPyrdjis",
      "metadata": {
        "id": "FWKfCPyrdjis"
      },
      "outputs": [],
      "source": [
        "from typing import List, Tuple\n",
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "def get_rules(text: str) -> List[str]:\n",
        "    text = clean_text(text)\n",
        "    sentences = get_sentences_from_text(text)\n",
        "    \n",
        "    GROUP_STEP_OFFSET = 2\n",
        "    # I create groups of 4 sentences to speed up the process of finding connected sentences\n",
        "    # and to make sure to find connected sentences not immediately adjacent\n",
        "    sentences_groups = [sentences[i:min(i+4, len(sentences))] for i in range(0, len(sentences) - 2, GROUP_STEP_OFFSET)]\n",
        "    doc_groups = nlp.pipe(['.'.join(map(lambda s: s.content, group)) for group in sentences_groups])\n",
        "\n",
        "    cluster_groups = []\n",
        "    for i, group in enumerate(sentences_groups):\n",
        "        group_text = next(doc_groups)\n",
        "        group_coref_clusters = convert_result_to_cluster(group_text, nlp.pipeline)\n",
        "        group_sentence_clusters = get_sentences_from_clusters(group_coref_clusters, group)\n",
        "        # + i * GROUP_STEP_OFFSET to retrieve the actual index of the sentence\n",
        "        cluster_groups.extend([sentence_id + i * GROUP_STEP_OFFSET for sentence_id in gsc] \n",
        "                               for gsc in group_sentence_clusters)\n",
        "        \n",
        "    rule_groups = get_rule_groups_from_sentence_clusters(sentences, cluster_groups)                                                                                \n",
        "    \n",
        "    return ['. '.join([sentences[s_index].content for s_index in group]) for group in rule_groups]\n",
        "\n",
        "text = get_document_by_id(DATASET_FILE_PATH, 24770)\n",
        "rules = get_rules(text)\n",
        "\n",
        "rules"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "from collections import Counter, defaultdict\n",
        "from typing import List, Dict\n",
        "\n",
        "def filter_tokens_as_components(doc: spacy.tokens.Doc) -> Dict[str, List[spacy.tokens.Token]]:\n",
        "    tokens_dict = defaultdict(list)\n",
        "\n",
        "    for token in doc:\n",
        "        if len(token) >= 3 and \\\n",
        "            token.pos_ in ['NOUN', 'PROPN'] and \\\n",
        "            token.dep_ in ['nsubj', 'dobj', 'nsubjpass', 'pobj', 'compound']:\n",
        "            tokens_dict[token.lemma_.lower()].append(token)\n",
        "           \n",
        "    return tokens_dict\n",
        "\n",
        "def find_n_most_common_nouns(n, docs: List[spacy.tokens.Doc]) -> List[str]:\n",
        "    docs_sets = [set(filter_tokens_as_components(doc).keys())\n",
        "                 for doc in docs]\n",
        "    all_tokens_from_docs = itertools.chain(*docs_sets)\n",
        "    tokens_counter = Counter(all_tokens_from_docs)\n",
        "    return tokens_counter.most_common(n)\n",
        "    \n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "df_dataset = get_df_with_docs(DATASET_FILE_PATH, 10, 50)\n",
        "docs = nlp.pipe(map(clean_text, df_dataset['rulebook'].values))\n",
        "\n",
        "find_n_most_common_nouns(10, docs)"
      ],
      "metadata": {
        "id": "w-JVFrfg4BwA"
      },
      "id": "w-JVFrfg4BwA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "from collections import namedtuple\n",
        "from spacy.matcher import Matcher, DependencyMatcher\n",
        "\n",
        "LuckMetrics = namedtuple('LuckMetrics', ['dice_based', 'drawing_based', 'shuffling_based', 'random_based'])\n",
        "\n",
        "def get_luck_metrics(doc: spacy.tokens.Doc) -> LuckMetrics:\n",
        "    # ---------- random ----------\n",
        "    random_matcher = Matcher(doc.vocab)\n",
        "    random_patterns_match = [\n",
        "        [{\"LEMMA\": { \"IN\": [\"random\", \"randomly\"]}}]\n",
        "    ]\n",
        "    random_matcher.add(\"random\", random_patterns_match)\n",
        "\n",
        "    # ---------- shuffle ----------\n",
        "    shuffle_matcher = Matcher(doc.vocab)\n",
        "    shuffle_patterns_match = [\n",
        "        [{\"LEMMA\": \"shuffle\", \"POS\": \"VERB\"}]\n",
        "    ]\n",
        "    shuffle_matcher.add(\"shuffle\", shuffle_patterns_match)\n",
        "\n",
        "    # ---------- card drawing ----------\n",
        "    drawing_matcher = DependencyMatcher(doc.vocab)    \n",
        "    drawing_patterns = [\n",
        "        [\n",
        "            {\n",
        "                \"RIGHT_ID\": \"drawing\",\n",
        "                \"RIGHT_ATTRS\": {\"LEMMA\": \"draw\", \"POS\": \"VERB\"}\n",
        "            },\n",
        "            {\n",
        "                \"LEFT_ID\": \"drawing\",\n",
        "                \"REL_OP\": \">\",\n",
        "                \"RIGHT_ID\": \"card\",\n",
        "                \"RIGHT_ATTRS\": {\n",
        "                    \"LEMMA\": \"card\",\n",
        "                    \"POS\": \"NOUN\", \n",
        "                    \"DEP\": { \"IN\": ['dobj', 'nsubjpass', 'compound'] }\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "    ]\n",
        "    drawing_matcher.add(\"drawing\", drawing_patterns)\n",
        "    # ---------- dice rolling ----------\n",
        "    dice_matcher = DependencyMatcher(doc.vocab)    \n",
        "    dice_patterns = [\n",
        "        [\n",
        "            {\n",
        "                \"RIGHT_ID\": \"rolling\",\n",
        "                \"RIGHT_ATTRS\": {\"LEMMA\": { \"IN\": [\"use\", \"throw\", \"roll\"]}, \"POS\": \"VERB\"}\n",
        "            },\n",
        "            {\n",
        "                \"LEFT_ID\": \"rolling\",\n",
        "                \"REL_OP\": \">\",\n",
        "                \"RIGHT_ID\": \"dice_or_die\",\n",
        "                \"RIGHT_ATTRS\": {\n",
        "                    \"LEMMA\": { \"IN\": [\"die\", \"dice\"]},\n",
        "                    \"POS\": \"NOUN\", \n",
        "                    \"DEP\": { \"IN\": ['nsubj', 'dobj', 'nsubjpass', 'compound'] }\n",
        "                }\n",
        "            }\n",
        "        ],\n",
        "        [\n",
        "            {\n",
        "                \"RIGHT_ID\": \"rolling\",\n",
        "                \"RIGHT_ATTRS\": {\"LEMMA\": { \"IN\": [\"use\", \"throw\", \"roll\"]}, \"POS\": \"VERB\"}\n",
        "            },\n",
        "            {\n",
        "                \"LEFT_ID\": \"rolling\",\n",
        "                \"REL_OP\": \">\",\n",
        "                \"RIGHT_ID\": \"number\",\n",
        "                \"RIGHT_ATTRS\": {\n",
        "                    \"IS_DIGIT\": True, \n",
        "                    \"DEP\": { \"IN\": ['dobj'] }\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "    ]\n",
        "    dice_matcher.add(\"diceroll\", dice_patterns)\n",
        "\n",
        "    dice_matches = dice_matcher(doc) \n",
        "    draw_matches = drawing_matcher(doc)\n",
        "    shuffle_matches = shuffle_matcher(doc)\n",
        "    random_matches = random_matcher(doc)\n",
        "\n",
        "    # TODO: needs normalization? (divide by rulebook length or tokens)\n",
        "\n",
        "    return LuckMetrics(len(dice_matches), len(draw_matches), len(shuffle_matches), len(random_matches))\n",
        "\n",
        "text = get_document_by_line(DATASET_FILE_PATH, 130)\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(clean_text(text))\n",
        "print(len(doc), len(doc.text))\n",
        "print(get_luck_metrics(doc))\n",
        "\n",
        "# displacy.render(doc, style='dep', jupyter=True)"
      ],
      "metadata": {
        "id": "Ayy4X1vaYYCj",
        "outputId": "2a3ac229-4931-4a2d-f9c7-236442fefc57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Ayy4X1vaYYCj",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['page', '1', 'of', '4', '\"', 'wizardology', '\"', 'GAME', 'play', 'objective', ':', 'to', 'become', 'a', 'Master', 'Wizard', 'by', 'collect', '4', 'talisman', '(', 'a', 'familiar', ',', 'a', 'wizard', \"'s\", 'hat', ',', 'a', 'staff', ',', 'and', 'an', 'amulet', ')', 'and', 'free', 'Merlin', \"'s\", 'spirit', 'from', 'the', 'old', 'oak', 'tree', '.', 'place', 'the', 'maze', 'board', 'in', 'the', 'center', 'of', 'the', 'table', '.', 'place', 'a', 'Spirit', 'Chamber', 'at', 'each', 'of', 'the', '4', 'open', 'outer', 'doorway', 'of', 'the', 'game', 'board', '.', 'place', 'the', 'familiar', 'die', 'and', 'the', 'familiar', 'in', 'the', 'Water', 'Spirit', 'Chamber', '.', 'place', 'the', 'Dragon', 'Medallion', 'and', 'the', 'wizard', 'hat', 'in', 'the', 'Air', 'Spirit', 'Chamber', '.', 'place', 'the', 'cup', 'with', 'the', 'wizard', 'staff', 'inside', 'it', 'in', 'the', 'Fire', 'Spirit', 'Chamber', '.', 'place', 'the', 'magic', 'wand', ',', 'levitation', 'magnet', 'and', 'amulet', 'in', 'the', 'Earth', 'Spirit', 'Chamber', '.', 'each', 'player', 'select', 'a', 'wizard', 'whose', 'path', 'he', 'or', 'she', 'wish', 'to', 'follow', 'and', 'place', 'the', 'wizard', 'figure', 'in', 'the', 'center', 'of', 'the', 'maze', '.', 'shuffle', 'the', 'Magical', 'Item', 'Cards', ',', 'Crystal', 'Ball', 'Cards', ',', 'and', 'Phoenix', 'Feather', 'Cards', '.', 'keep', 'each', 'deck', 'separate', 'and', 'put', 'they', 'to', 'the', 'side', '.', 'place', 'the', 'Spells', 'and', 'Potions', 'book', 'and', 'dice', 'off', 'to', 'the', 'side', '.', 'play', 'the', 'GAME', ':', 'your', 'goal', 'be', 'to', 'collect', 'all', '4', 'talisman', '.', 'you', 'do', 'this', 'by', 'successfully', 'move', 'around', 'the', 'maze', 'and', 'collect', 'card', 'that', 'will', 'help', 'you', 'collect', 'the', 'talisman', '.', 'you', 'may', 'also', 'duel', 'other', 'apprentice', 'for', 'their', 'card', '.', 'each', 'apprentice', 'roll', 'the', 'double', 'die', '.', 'the', 'high', 'roller', 'go', 'first', 'and', 'play', 'continue', 'clockwise', '.', 'the', 'board', 'be', 'a', 'maze', ',', 'so', 'the', 'first', 'challenge', 'lie', 'in', 'choose', 'which', 'direction', 'to', 'take', '.', 'the', 'center', ',', 'as', 'well', 'as', 'the', 'different', 'ring', 'of', 'the', 'maze', 'be', 'mark', 'with', 'open', 'doorway', 'to', 'enter', 'or', 'leave', 'by', '.', 'each', 'apprentice', 'must', 'find', 'his', 'or', 'her', 'way', 'through', 'the', 'maze', 'to', 'visit', 'each', 'of', 'the', '4', 'outer', 'Spirit', 'Chambers', 'to', 'collect', 'the', 'talisman', '.', 'there', 'be', 'no', 'order', 'in', 'which', 'the', 'Spirit', 'Chambers', 'must', 'be', 'visit', '.', 'when', 'navigate', 'the', 'maze', ',', 'if', 'an', 'apprentice', 'reach', 'a', 'dead', '-', 'end', ',', 'he', 'or', 'she', 'may', 'bounce', 'off', 'the', 'wall', 'to', 'continue', 'move', '.', 'for', 'example', ',', 'if', 'you', 'roll', 'a', '5', 'and', 'be', 'only', '2', 'space', 'from', 'the', 'dead', '-', 'end', ',', 'you', 'may', 'move', '2', 'space', 'then', 'bounce', 'back', 'for', 'move', '3', ',', '4', ',', 'and', '5', '.', 'dead', '-', 'end', 'be', 'normally', 'lock', ',', 'but', 'can', 'be', 'open', 'if', 'you', 'have', 'the', '\"', 'Open', 'Sesame', '\"', 'Card', '.', 'the', 'spaces', 'on', 'the', 'BOARD', ':', '1', '.', 'Magical', 'Items', ':', 'draw', 'one', 'card', 'from', 'the', 'Magic', 'Item', 'deck', '.', 'Magical', 'Item', 'Cards', 'be', 'key', 'to', 'enter', 'the', 'Spirit', 'Chambers', '-', 'you', 'can', 'not', 'gain', 'access', 'to', 'a', 'particular', 'chamber', 'without', 'the', 'card', 'that', 'correspond', 'to', 'it', '.', 'the', 'more', 'Magical', 'Item', 'Cards', 'an', 'apprentice', 'have', ',', 'the', 'more', 'chance', 'there', 'will', 'be', 'to', 'successfully', 'attempt', 'each', 'task', '.', 'Animal', 'Magic', 'Guide', 'Book', ':', 'the', 'key', 'to', 'enter', 'the', 'Water', 'Spirit', 'Chamber', 'Dragon', 'Medallion', ':', 'the', 'key', 'to', 'enter', 'the', 'Air', 'Spirit', 'Chamber', '.', 'athame', ':', 'key', 'to', 'enter', 'the', 'Fire', 'Spirit', 'Chamber', 'Ring', 'of', 'Power', ':', 'key', 'to', 'enter', 'the', 'Earth', 'Spirit', 'Chamber', '.', 'Wild', 'Cards', ':', 'these', 'card', 'can', 'be', 'use', 'to', 'represent', 'any', 'of', 'the', '4', 'Magical', 'Items', 'you', 'wish', '.', 'release', 'a', 'Genie', ':', 'roll', 'the', 'double', 'die', '.', 'if', 'the', 'outer', 'die', 'be', 'high', 'than', 'the', 'inner', 'die', ',', 'the', 'apprentice', 'have', 'successfully', 'release', 'a', 'genie', '.', 'he', 'or', 'she', 'then', 'move', 'to', 'the', 'Spirit', 'Chamber', 'name', 'on', 'that', 'card', '.', 'if', 'the', 'apprentice', 'have', 'the', 'Magical', 'Item', 'Card', 'for', 'that', 'particular', 'Spirit', 'Chamber', ',', 'he', 'can', 'perform', 'the', 'task', 'require', 'to', 'earn', 'a', 'talisman', '.', 'if', 'the', 'apprentice', 'do', 'not', 'have', 'the', 'Magical', 'Item', 'Card', ',', 'the', 'turn', 'be', 'over', '.', 'he', 'leave', 'the', 'Spirit', 'Chamber', 'on', 'his', 'next', 'turn', '.', 'if', 'the', 'inner', 'die', 'be', 'high', 'than', 'the', 'outer', ',', 'or', 'a', 'tie', 'occur', ',', 'the', 'apprentice', 'have', 'fail', 'to', 'release', 'the', 'genie', 'and', 'the', 'turn', 'be', 'over', '.', 'Fairy', 'Flag', ':', 'if', 'you', 'draw', 'this', 'card', ',', 'you', 'instantly', 'earn', 'a', 'talisman', 'of', 'choice', '.', 'there', 'be', 'no', 'need', 'to', 'go', 'to', 'the', 'Spirit', 'Chamber', 'or', 'perform', 'the', 'task', '!', '5', '.', 'hand', 'of', 'glory', ':', 'this', 'allow', 'an', 'apprentice', 'to', 'steal', 'a', 'talisman', 'from', 'any', 'other', 'player', '.', 'take', 'the', 'talisman', 'of', 'choice', 'from', 'another', 'player', ',', 'return', 'it', 'to', 'the', 'Spirit', 'Chamber', 'it', 'come', 'from', ',', 'then', 'take', 'your', 'corresponding', 'talisman', '.', 'Kee', \"'s\", 'Locator', ':', 'if', 'a', 'Hand', 'of', 'Glory', 'card', 'be', 'use', 'on', 'you', 'to', 'steal', 'one', 'of', 'your', 'talisman', ',', 'this', 'card', 'will', 'help', 'get', 'it', 'back', '.', 'you', 'must', 'return', 'to', 'the', 'Spirit', 'Chamber', 'of', 'the', 'talisman', 'that', 'be', 'steal', 'and', 'present', 'this', 'card', '.', 'you', 'will', 'not', 'need', 'to', 'perfrom', 'the', 'task', '-', 'the', 'steal', 'talisman', 'will', 'be', 'instantly', 'return', '.', 'happiness', 'Spell', ':', 'this', 'be', 'an', '\"', 'all', 'play', '\"', 'card', '.', 'each', 'apprentice', 'roll', 'the', 'double', 'die', '.', 'whoever', 'roll', 'the', 'high', 'combination', 'will', 'be', 'the', 'happy', 'and', 'be', 'allow', 'to', 'move', 'that', 'number', 'of', 'space', '.', 'play', 'continue', 'clockwise', 'from', 'the', 'winner', '.', 'dowsing', ':', 'if', 'you', 'pick', 'this', 'card', ',', 'you', 'must', 'blind', 'draw', 'a', 'Magical', 'Item', 'Card', 'from', 'an', 'opponent', 'of', 'choice', '.', 'open', 'Sesame', ':', 'this', 'card', 'allow', 'an', 'apprentice', 'to', 'move', 'directly', 'through', 'a', 'wall', 'mark', 'with', 'a', 'lock', '.', 'once', 'the', 'player', 'have', 'unlock', 'a', 'wall', 'and', 'go', 'through', ',', 'it', 'becomes', 'lock', 'again', '.', 'Vivienne', \"'s\", 'Circle', ':', 'a', 'powerful', 'card', 'to', 'have', ',', 'as', 'it', 'protect', 'you', 'from', 'the', 'follow', 'magical', 'attack', ':', 'dowsing', ',', 'Hand', 'of', 'Glory', ',', 'Magical', 'Duels', 'and', 'Elf', 'Charms', '.', 'Wind', 'Knot', ':', 'this', 'card', 'can', 'really', 'give', 'you', 'the', 'advantage', 'against', 'your', 'opponent', '.', 'it', 'allow', 'an', 'apprentice', 'to', 'rotate', 'a', 'quarter', 'of', 'the', 'way', 'in', 'either', 'direction', '.', 'whether', 'you', 'rotate', 'to', 'the', 'right', 'or', 'to', 'the', 'left', ',', 'you', 'must', 'always', 'make', 'sure', 'that', 'the', 'doorway', 'line', 'up', 'with', 'a', 'Spirit', 'Chamber', '.', 'this', 'allow', 'player', 'to', 'move', 'themselves', 'close', 'to', 'a', 'Spirit', 'Chamber', 'they', 'may', 'need', 'to', 'get', 'to', ',', 'or', 'to', 'move', 'an', 'opponent', 'far', 'away', 'from', 'one', '.', 'false', 'Prophecy', ':', 'if', 'you', 'draw', 'this', 'card', ',', 'you', 'must', 'start', 'over', 'again', 'from', 'the', 'center', 'of', 'the', 'maze', '.', 'you', 'still', 'keep', 'everything', 'you', 'have', 'collect', 'so', 'far', '.', 'Phoenix', 'feather', ':', 'draw', 'one', 'card', 'from', 'the', 'Phoenix', 'Feather', 'deck', '.', 'these', 'card', 'help', 'transport', 'apprentice', 'around', 'the', 'maze', 'more', 'quickly', '.', 'Phoenix', 'Feather', 'Cards', 'do', 'not', 'have', 'to', 'be', 'use', 'right', 'away', ',', 'but', 'can', 'be', 'keep', 'for', 'later', 'use', '.', 'there', 'be', '3', 'different', 'type', 'of', 'flight', ':', 'seven', 'League', 'boot', ':', 'this', 'card', 'allow', 'an', 'apprentice', 'to', 'travel', 'to', 'any', 'space', 'on', 'the', 'ring', 'he', 'or', 'she', 'currently', 'occupy', '.', 'the', 'boot', 'have', 'limit', ',', 'though', '.', 'if', 'a', 'wall', 'be', 'in', 'your', 'way', ',', 'you', 'can', 'not', 'go', 'through', 'it', ',', 'unless', 'you', 'possess', 'an', '\"', 'Open', 'Sesame', '\"', 'Card', '.', 'Broomstick', ':', 'before', 'be', 'able', 'to', 'use', 'a', 'Broomstick', 'Card', ',', 'the', 'apprentice', 'must', 'roll', 'the', 'die', '.', 'if', 'an', 'even', 'number', 'be', 'roll', ',', 'the', 'broomstick', \"'s\", 'magic', 'be', 'work', 'in', 'the', 'apprentice', \"'\", 'favor', 'and', 'movement', 'to', 'anywhere', 'in', 'the', 'maze', ',', 'include', 'the', '4', 'Spirit', 'Chambers', ',', 'be', 'allow', '.', 'an', 'odd', 'number', 'prove', 'the', 'broomstick', 'useless', '-', 'the', 'card', 'should', 'be', 'discard', 'and', 'the', 'apprentice', 'turn', 'be', 'over', '.', 'Magic', 'Carpet', ':', 'the', 'good', 'mean', 'of', 'flight', '!', 'an', 'apprentice', 'can', 'fly', 'anywhere', 'on', 'the', 'maze', ',', 'include', 'the', 'Spirit', 'Chambers', '.', 'if', 'an', 'apprentice', 'be', 'wise', 'he', 'or', 'she', 'will', 'hold', 'onto', 'at', 'least', 'one', 'Magic', 'Carpet', 'Card', 'during', 'the', 'course', 'of', 'the', 'game', '.', 'this', 'will', 'prove', 'to', 'be', 'quite', 'useful', 'when', 'return', 'to', 'the', 'enter', 'for', 'the', 'final', 'task', 'of', 'free', 'Merlin', '!', 'page', '3', 'of', '4', '14', '.', 'roll', 'double', 'die', ':', 'roll', 'the', 'double', 'die', 'and', 'move', 'the', 'combine', 'amount', 'of', 'the', 'inner', 'and', 'outer', 'die', '.', 'lose', 'a', 'turn', ':', 'the', 'apprentice', 'lose', 'their', 'turn', '.', 'Spells', 'and', 'Potions', ':', 'an', 'apprentice', 'must', 'roll', 'the', 'Spells', 'and', 'Potions', 'dice', 'after', 'land', 'here', '.', 'one', 'die', 'be', 'mark', 'with', 'a', 'symbol', ',', 'the', 'other', 'with', 'a', 'color', '.', 'the', 'combination', 'determine', 'which', 'spell', 'or', 'potion', 'you', 'have', 'perform', 'and', 'whether', 'or', 'not', 'you', 'have', 'perform', 'it', 'successfully', '.', 'refer', 'to', 'the', 'Spells', 'and', 'Potions', 'book', 'to', 'look', 'up', 'your', 'combination', 'and', 'find', 'out', 'the', 'result', 'of', 'your', 'roll', '.', 'the', 'Alchemy', 'lab', ':', 'roll', 'certain', 'combination', 'on', 'the', 'Spells', 'and', 'Potions', 'dice', 'will', 'land', 'an', 'apprentice', 'in', 'the', 'Alchemy', 'Lab', '.', 'on', 'his', 'or', 'her', 'next', 'turn', ',', 'the', 'apprentice', 'must', 'attempt', 'to', 'escape', 'by', 'roll', 'the', 'same', 'combination', 'on', 'the', 'Spells', 'and', 'Potions', 'dice', 'that', 'have', 'originally', 'send', 'he', 'or', 'she', 'here', '.', 'an', 'apprentice', 'have', 'only', '3', 'chance', 'per', 'turn', 'to', 'get', 'out', '.', 'he', 'or', 'she', 'must', 'stay', 'there', 'for', 'as', 'many', 'turn', 'as', 'it', 'take', 'to', 'get', 'out', '.', 'if', 'a', 'player', 'land', 'here', 'during', 'the', 'normal', 'course', 'of', 'play', 'it', 'should', 'be', 'treat', 'as', 'a', 'blank', 'space', '.', 'secret', 'path', ':', 'if', 'an', 'apprentice', 'land', 'on', 'a', 'secret', 'Path', 'space', ',', 'he', 'or', 'she', 'may', 'move', 'directly', 'to', 'any', 'other', 'secret', 'Path', 'space', 'mark', 'on', 'the', 'maze', '.', 'the', 'apprentice', 'will', 'begin', 'from', 'this', 'new', 'space', 'on', 'his', 'or', 'her', 'next', 'turn', '.', 'Crystal', 'Ball', ':', 'an', 'apprentice', 'must', 'draw', 'from', 'the', 'Crystal', 'Ball', 'deck', 'after', 'land', 'on', 'this', 'space', '.', 'it', 'be', 'not', 'always', 'wise', 'to', 'consult', 'a', 'Crystal', 'Ball', '.', 'some', 'thing', 'you', 'see', 'in', 'the', 'ball', 'may', 'be', 'good', ',', 'some', 'may', 'be', 'bad', '.', 'draw', 'from', 'this', 'deck', 'at', 'your', 'own', 'risk', '!', '20', '.', 'Elf', 'Charm', ':', 'if', 'you', 'pick', 'this', 'card', ',', 'you', 'must', 'blind', 'draw', 'a', 'Phoenix', 'Feather', 'Card', 'from', 'an', 'apprentice', 'of', 'choice', '.', 'the', 'TASKS', ':', 'when', 'you', 'reach', 'a', 'Spirit', 'Chamber', ',', 'you', 'immediately', 'perform', 'the', 'task', 'require', 'to', 'earn', 'that', 'particular', 'talisman', '.', 'familiar', ':', 'in', 'the', 'Water', 'Spirit', 'Chamber', 'you', 'call', 'upon', 'the', 'playful', 'spirit', ',', 'Gladde', ',', 'to', 'help', 'you', 'summon', 'your', 'Familiar', '.', 'use', 'the', 'double', 'die', 'and', 'the', 'Familiar', 'die', 'for', 'this', 'task', '.', 'first', 'roll', 'the', 'double', 'die', '.', 'the', 'outer', 'die', 'will', 'determine', 'the', 'amount', 'of', 'chance', 'you', 'have', 'to', 'roll', 'the', 'Familiar', 'die', '.', 'for', 'example', ',', 'if', 'you', 'be', 'the', 'Lapp', 'Shaman', 'and', 'you', 'roll', 'a', '5', 'on', 'the', 'outer', 'double', 'die', ',', 'you', 'have', '5', 'chance', 'to', 'roll', 'Gumpi', ',', 'the', 'wolf', ',', 'on', 'the', 'Familiar', 'die', '.', 'if', 'you', 'fail', ',', 'you', 'must', 'try', 'again', ',', 'but', 'only', 'if', 'you', 'have', 'another', 'Animal', 'Magic', 'Guide', 'Book', 'Card', 'to', 'use', 'on', 'your', 'next', 'turn', '.', 'if', 'you', 'do', 'not', 'have', 'another', 'Animal', 'Magic', 'Guide', 'Book', 'Card', ',', 'you', 'must', 'leave', 'the', 'Spirit', 'Chamber', 'in', 'search', 'of', 'another', '.', 'Wizard', 'Staff', ':', 'in', 'the', 'Fire', 'Spirit', 'Chamber', ',', 'you', 'will', 'summon', 'the', 'spirit', 'Pranxtor', 'to', 'help', 'you', 'earn', 'your', 'Wizard', 'staff', '.', 'you', 'will', 'blind', 'draw', 'a', 'staff', 'from', 'the', 'cup', '.', 'if', 'you', 'succeed', 'in', 'draw', 'your', 'colored', 'staff', ',', 'place', 'the', 'staff', 'into', 'the', 'arm', 'of', 'your', 'wizard', 'piece', '.', 'if', 'you', 'draw', 'a', 'staff', 'whose', 'color', 'do', 'not', 'match', 'your', 'wizard', ',', 'or', 'the', 'neutral', 'staff', ',', 'you', 'have', 'fail', '.', 'place', 'the', 'staff', 'back', 'into', 'Pranxtor', \"'s\", 'cup', '.', 'you', 'may', 'try', 'again', 'if', 'you', 'have', 'another', 'Athame', 'Card', 'to', 'use', 'on', 'your', 'next', 'turn', '.', 'if', 'you', 'do', 'not', 'have', 'another', 'Athame', 'Card', ',', 'you', 'must', 'leave', 'the', 'Spirit', 'Chamber', 'in', 'search', 'of', 'another', '.', 'Wizard', 'Hat', ':', 'in', 'the', 'Air', 'Spirit', 'Chamber', 'you', 'will', 'call', 'upon', 'the', 'spirit', 'Jaypes', 'to', 'help', 'you', 'locate', 'a', 'magical', 'beast', '.', 'take', 'the', 'Dragon', 'Medallion', 'and', 'flip', 'it', 'like', 'a', 'coin', '.', 'if', 'the', 'dragon', 'land', 'face', 'up', ',', 'you', 'have', 'locate', 'a', 'dragon', 'and', 'have', 'earn', 'a', 'hat', '.', 'place', 'the', 'appropriate', 'hat', 'on', 'the', 'head', 'of', 'your', 'wizard', 'piece', '.', 'if', 'the', 'egg', 'land', 'face', 'up', ',', 'you', 'have', 'fail', 'this', 'task', 'and', 'must', 'try', 'again', ',', 'but', 'only', 'if', 'you', 'have', 'another', 'Dragon', 'Medallion', 'Card', '.', 'if', 'you', 'do', 'not', 'have', 'another', 'Dragon', 'Medallion', 'Card', ',', 'you', 'must', 'leave', 'the', 'Spirit', 'Chamber', 'in', 'search', 'of', 'another', '.', 'amulet', ':', 'in', 'the', 'Earth', 'Spirit', 'Chamber', 'you', 'will', 'call', 'upon', 'the', 'spirit', 'Larfor', 'to', 'help', 'you', 'perform', 'a', 'special', 'magic', 'trick', '.', 'an', 'oppose', 'apprentice', 'must', 'hold', 'the', 'magic', 'wand', 'and', 'place', 'the', 'first', 'of', '2', 'identical', 'levitate', 'magnet', 'onto', 'it', '.', 'you', 'must', 'then', 'place', 'the', 'second', 'magnet', 'on', 'the', 'wand', '-', 'guess', 'which', 'way', 'to', 'put', 'it', '.', 'if', 'the', 'magnet', 'levitate', ',', 'you', 'have', 'succeed', 'and', 'can', 'collect', 'your', 'amulet', '.', 'if', 'the', 'magnet', 'fall', ',', 'you', 'have', 'fail', 'and', 'must', 'try', 'again', ',', 'but', 'only', 'if', 'you', 'have', 'another', 'Ring', 'of', 'Power', 'Card', 'to', 'use', 'on', 'your', 'next', 'turn', '.', 'if', 'you', 'do', 'not', 'have', 'another', 'Ring', 'of', 'PowerCard', 'you', 'must', 'leave', 'the', 'Spirit', 'Chamber', 'in', 'search', 'of', 'another', '.', 'magical', 'duel', ':', 'if', 'you', 'land', 'on', 'the', 'same', 'space', 'as', 'another', 'apprentice', ',', 'you', 'may', 'challenge', 'that', 'player', 'to', 'a', 'Magical', 'Duel', '.', 'before', 'duel', 'begin', ',', 'the', 'challenging', 'apprentice', 'bet', 'a', 'certain', 'number', 'of', 'card', '.', 'any', 'amount', 'and', 'combination', 'of', 'card', 'can', 'be', 'use', ',', 'but', 'you', 'can', 'not', 'bet', 'more', 'card', 'than', 'the', 'other', 'player', 'have', '.', 'each', 'apprentice', 'then', 'take', 'one', 'set', 'of', 'Magical', 'Duel', 'Cards', '.', 'each', 'set', 'consist', 'of', '3', 'attack', 'card', ':', 'Spell', ',', 'Potion', ',', 'and', 'Chant', '.', 'the', 'duel', 'player', 'shuffle', 'their', 'card', '.', 'then', ',', 'each', 'player', 'place', 'the', 'first', '2', 'card', 'face', 'down', 'and', 'flip', 'the', 'third', 'card', 'over', 'to', 'reveal', 'the', 'attack', '.', 'the', 'card', 'score', 'as', 'follow', ':', 'Spell', 'beat', 'Potion', ',', 'potion', 'beat', 'Chant', ',', 'and', 'change', 'beat', 'Spell', '.', 'in', 'the', 'case', 'of', 'a', 'tie', '.', 'apprentice', 're', '-', 'shuffle', 'their', 'card', 'and', 'start', 'again', 'until', 'there', 'be', 'a', 'winner', '.', 'the', 'winner', 'take', 'as', 'many', 'card', 'as', 'be', 'bet', 'from', 'the', 'other', 'player', '.', 'if', 'you', 'land', 'on', 'a', 'Magical', 'Duel', 'space', ',', 'move', 'directly', 'to', 'another', 'player', \"'s\", 'space', 'to', 'begin', 'a', 'duel', '.', 'the', 'challenge', 'player', 'do', 'not', 'abide', 'by', 'the', 'rule', 'of', 'the', 'space', 'he', 'or', 'she', 'have', 'move', 'to', '.', 'win', 'the', 'GAME', ':', 'once', 'you', 'have', 'complete', 'all', '4', 'task', 'and', 'have', 'in', 'your', 'possession', 'the', '4', 'talisman', ',', 'you', 'be', 'no', 'long', 'an', 'apprentice', ',', 'but', 'be', 'worthy', 'of', 'the', 'title', 'of', '\"', 'WizardYou', 'may', 'now', 'proceed', 'back', 'to', 'the', 'center', 'of', 'the', 'maze', 'to', 'perfrom', 'the', 'final', 'test', '.', 'if', 'you', 'have', 'a', 'Magic', 'Carpet', 'Card', ',', 'it', 'would', 'be', 'wise', 'to', 'use', 'it', 'now', 'to', 'fly', 'directly', 'to', 'the', 'center', '.', 'if', 'not', ',', 'you', 'must', 'travel', 'back', 'to', 'the', 'center', 'through', 'the', 'maze', '.', 'this', 'be', 'dangerous', 'because', 'it', 'leave', 'you', 'open', 'to', 'lose', 'your', 'talisman', 'along', 'the', 'way', '.', 'if', 'you', 'make', 'it', 'to', 'the', 'center', 'unscathed', ',', 'you', 'be', 'safe', '!', '3', '.', 'in', 'order', 'to', 'free', 'Merlin', ',', 'you', 'must', 'roll', 'a', 'combination', 'of', '7', 'with', 'the', 'double', 'die', ':', '4', 'and', '3', ',', '5', 'and', '2', 'or', '6', 'and', '1', '.', 'you', 'get', 'only', 'one', 'chance', 'per', 'turn', '.', 'if', 'you', 'successfully', 'roll', 'a', '7', ',', 'you', 'have', 'free', 'Merlin', 'and', 'win', 'the', 'game', '!', '5', '.', 'beware', '!', 'if', 'you', 'roll', 'a', 'combination', 'of', '3', '(', '2', 'and', '1', ')', ',', 'the', '\"', 'Rule', 'of', 'Three', '\"', 'apply', 'and', 'you', 'will', 'be', 'send', 'back', 'to', 'the', 'last', 'Spirit', 'Chamber', 'you', 'visit', '.', 'you', 'must', 'travel', 'back', 'to', 'the', 'center', 'to', 'try', 'again', '!']\n",
            "2603 12372\n",
            "LuckMetrics(dice_based=12, drawing_based=4, shuffling_based=3, random_based=0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''you can only take this because it can be outrageous. \n",
        "    you can't take it. you could not also choose. you may never be sure of the result. \n",
        "    you can decide the next thing.'''\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(clean_text(text))\n",
        "print([token.lemma_ for token in doc])\n",
        "print(len(doc), len(doc.text))\n",
        "\n",
        "displacy.render(doc, style='dep', jupyter=True)"
      ],
      "metadata": {
        "id": "I3JtzI3p9lvj",
        "outputId": "b40b6e15-a1d7-4645-c529-876d6018f530",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        }
      },
      "id": "I3JtzI3p9lvj",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['you', 'can', 'only', 'take', 'this', 'because', 'it', 'can', 'be', 'outrageous', '.', 'you', 'can', 'not', 'take', 'it', '.', 'you', 'could', 'not', 'also', 'choose', '.', 'you', 'may', 'never', 'be', 'sure', 'of', 'the', 'result', '.', 'you', 'can', 'decide', 'the', 'next', 'thing']\n",
            "38 165\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"f9960c669afd49b19c47f7eb92302dff-0\" class=\"displacy\" width=\"6000\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">you</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">can</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">only</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">take</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">this</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">because</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">SCONJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">it</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">can</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">be</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">outrageous.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">you</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">ca</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">n't</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">PART</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">take</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">it.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">you</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">could</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">not</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">PART</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">also</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3375\">choose.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3375\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3550\">you</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3550\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3725\">may</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3725\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3900\">never</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3900\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4075\">be</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4075\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4250\">sure</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4250\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4425\">of</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4425\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4600\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4600\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4775\">result.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4775\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4950\">you</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4950\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5125\">can</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5125\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5300\">decide</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5300\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5475\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5475\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5650\">next</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5650\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5825\">thing</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5825\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f9960c669afd49b19c47f7eb92302dff-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,89.5 570.0,89.5 570.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f9960c669afd49b19c47f7eb92302dff-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f9960c669afd49b19c47f7eb92302dff-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,177.0 565.0,177.0 565.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f9960c669afd49b19c47f7eb92302dff-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,354.0 L237,342.0 253,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f9960c669afd49b19c47f7eb92302dff-0-2\" stroke-width=\"2px\" d=\"M420,352.0 C420,264.5 560.0,264.5 560.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f9960c669afd49b19c47f7eb92302dff-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f9960c669afd49b19c47f7eb92302dff-0-3\" stroke-width=\"2px\" d=\"M595,352.0 C595,264.5 735.0,264.5 735.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f9960c669afd49b19c47f7eb92302dff-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M735.0,354.0 L743.0,342.0 727.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f9960c669afd49b19c47f7eb92302dff-0-4\" stroke-width=\"2px\" d=\"M945,352.0 C945,89.5 1445.0,89.5 1445.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f9960c669afd49b19c47f7eb92302dff-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M945,354.0 L937,342.0 953,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f9960c669afd49b19c47f7eb92302dff-0-5\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,177.0 1440.0,177.0 1440.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f9960c669afd49b19c47f7eb92302dff-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1120,354.0 L1112,342.0 1128,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f9960c669afd49b19c47f7eb92302dff-0-6\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,264.5 1435.0,264.5 1435.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f9960c669afd49b19c47f7eb92302dff-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1295,354.0 L1287,342.0 1303,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f9960c669afd49b19c47f7eb92302dff-0-7\" stroke-width=\"2px\" d=\"M595,352.0 C595,2.0 1450.0,2.0 1450.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f9960c669afd49b19c47f7eb92302dff-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advcl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1450.0,354.0 L1458.0,342.0 1442.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f9960c669afd49b19c47f7eb92302dff-0-8\" stroke-width=\"2px\" d=\"M1470,352.0 C1470,264.5 1610.0,264.5 1610.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f9960c669afd49b19c47f7eb92302dff-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1610.0,354.0 L1618.0,342.0 1602.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f9960c669afd49b19c47f7eb92302dff-0-9\" stroke-width=\"2px\" d=\"M1820,352.0 C1820,89.5 2320.0,89.5 2320.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f9960c669afd49b19c47f7eb92302dff-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1820,354.0 L1812,342.0 1828,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f9960c669afd49b19c47f7eb92302dff-0-10\" stroke-width=\"2px\" d=\"M1995,352.0 C1995,177.0 2315.0,177.0 2315.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f9960c669afd49b19c47f7eb92302dff-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1995,354.0 L1987,342.0 2003,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f9960c669afd49b19c47f7eb92302dff-0-11\" stroke-width=\"2px\" d=\"M2170,352.0 C2170,264.5 2310.0,264.5 2310.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f9960c669afd49b19c47f7eb92302dff-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">neg</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2170,354.0 L2162,342.0 2178,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f9960c669afd49b19c47f7eb92302dff-0-12\" stroke-width=\"2px\" d=\"M2345,352.0 C2345,264.5 2485.0,264.5 2485.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f9960c669afd49b19c47f7eb92302dff-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2485.0,354.0 L2493.0,342.0 2477.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f9960c669afd49b19c47f7eb92302dff-0-13\" stroke-width=\"2px\" d=\"M2695,352.0 C2695,2.0 3375.0,2.0 3375.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f9960c669afd49b19c47f7eb92302dff-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2695,354.0 L2687,342.0 2703,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f9960c669afd49b19c47f7eb92302dff-0-14\" stroke-width=\"2px\" d=\"M2870,352.0 C2870,89.5 3370.0,89.5 3370.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f9960c669afd49b19c47f7eb92302dff-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2870,354.0 L2862,342.0 2878,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f9960c669afd49b19c47f7eb92302dff-0-15\" stroke-width=\"2px\" d=\"M3045,352.0 C3045,177.0 3365.0,177.0 3365.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f9960c669afd49b19c47f7eb92302dff-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">neg</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3045,354.0 L3037,342.0 3053,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f9960c669afd49b19c47f7eb92302dff-0-16\" stroke-width=\"2px\" d=\"M3220,352.0 C3220,264.5 3360.0,264.5 3360.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f9960c669afd49b19c47f7eb92302dff-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3220,354.0 L3212,342.0 3228,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f9960c669afd49b19c47f7eb92302dff-0-17\" stroke-width=\"2px\" d=\"M3570,352.0 C3570,89.5 4070.0,89.5 4070.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f9960c669afd49b19c47f7eb92302dff-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3570,354.0 L3562,342.0 3578,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f9960c669afd49b19c47f7eb92302dff-0-18\" stroke-width=\"2px\" d=\"M3745,352.0 C3745,177.0 4065.0,177.0 4065.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f9960c669afd49b19c47f7eb92302dff-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3745,354.0 L3737,342.0 3753,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f9960c669afd49b19c47f7eb92302dff-0-19\" stroke-width=\"2px\" d=\"M3920,352.0 C3920,264.5 4060.0,264.5 4060.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f9960c669afd49b19c47f7eb92302dff-0-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">neg</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3920,354.0 L3912,342.0 3928,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f9960c669afd49b19c47f7eb92302dff-0-20\" stroke-width=\"2px\" d=\"M4095,352.0 C4095,264.5 4235.0,264.5 4235.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f9960c669afd49b19c47f7eb92302dff-0-20\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4235.0,354.0 L4243.0,342.0 4227.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f9960c669afd49b19c47f7eb92302dff-0-21\" stroke-width=\"2px\" d=\"M4270,352.0 C4270,264.5 4410.0,264.5 4410.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f9960c669afd49b19c47f7eb92302dff-0-21\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4410.0,354.0 L4418.0,342.0 4402.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f9960c669afd49b19c47f7eb92302dff-0-22\" stroke-width=\"2px\" d=\"M4620,352.0 C4620,264.5 4760.0,264.5 4760.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f9960c669afd49b19c47f7eb92302dff-0-22\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4620,354.0 L4612,342.0 4628,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f9960c669afd49b19c47f7eb92302dff-0-23\" stroke-width=\"2px\" d=\"M4445,352.0 C4445,177.0 4765.0,177.0 4765.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f9960c669afd49b19c47f7eb92302dff-0-23\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4765.0,354.0 L4773.0,342.0 4757.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f9960c669afd49b19c47f7eb92302dff-0-24\" stroke-width=\"2px\" d=\"M4970,352.0 C4970,177.0 5290.0,177.0 5290.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f9960c669afd49b19c47f7eb92302dff-0-24\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4970,354.0 L4962,342.0 4978,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f9960c669afd49b19c47f7eb92302dff-0-25\" stroke-width=\"2px\" d=\"M5145,352.0 C5145,264.5 5285.0,264.5 5285.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f9960c669afd49b19c47f7eb92302dff-0-25\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5145,354.0 L5137,342.0 5153,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f9960c669afd49b19c47f7eb92302dff-0-26\" stroke-width=\"2px\" d=\"M5495,352.0 C5495,177.0 5815.0,177.0 5815.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f9960c669afd49b19c47f7eb92302dff-0-26\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5495,354.0 L5487,342.0 5503,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f9960c669afd49b19c47f7eb92302dff-0-27\" stroke-width=\"2px\" d=\"M5670,352.0 C5670,264.5 5810.0,264.5 5810.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f9960c669afd49b19c47f7eb92302dff-0-27\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5670,354.0 L5662,342.0 5678,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f9960c669afd49b19c47f7eb92302dff-0-28\" stroke-width=\"2px\" d=\"M5320,352.0 C5320,89.5 5820.0,89.5 5820.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f9960c669afd49b19c47f7eb92302dff-0-28\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5820.0,354.0 L5828.0,342.0 5812.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "from collections import namedtuple\n",
        "from spacy.matcher import Matcher, DependencyMatcher\n",
        "\n",
        "def get_choices_amount_metric(doc: spacy.tokens.Doc) -> int:\n",
        "    # all can/could/may\n",
        "    can_could_may_matcher = Matcher(doc.vocab)\n",
        "    can_could_may_patterns = [\n",
        "        [{\"LEMMA\": { \"IN\": [\"can\", \"could\", \"may\"]}, \"POS\": \"AUX\"}]\n",
        "    ]\n",
        "    can_could_may_matcher.add('can_could_may', can_could_may_patterns)\n",
        "\n",
        "    can_could_may_matches = { match[1] for match in can_could_may_matcher(doc) }\n",
        "\n",
        "    can_could_may_without_neg_matcher = DependencyMatcher(doc.vocab)\n",
        "    # can/could/may with only or neg\n",
        "    can_could_may_without_neg_patterns = [\n",
        "        [\n",
        "            {\n",
        "                \"RIGHT_ID\": \"can_could_may\",\n",
        "                \"RIGHT_ATTRS\": {\n",
        "                    \"LEMMA\": { \"IN\": [\"can\", \"could\", \"may\"]}, \n",
        "                    \"POS\": \"AUX\"\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                \"LEFT_ID\": \"can_could_may\",\n",
        "                \"REL_OP\": \"<\",\n",
        "                \"RIGHT_ID\": \"generic_verb\",\n",
        "                \"RIGHT_ATTRS\": {\n",
        "                    \"POS\": { \"IN\": [\"AUX\", \"VERB\"] }\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                \"LEFT_ID\": \"generic_verb\",\n",
        "                \"REL_OP\": \">\",\n",
        "                \"RIGHT_ID\": \"neg_or_only\",\n",
        "                \"RIGHT_ATTRS\": {\n",
        "                    \"LEMMA\": { \"IN\": [\"not\", \"only\", \"never\"]}, \n",
        "                    \"DEP\": { \"IN\": [\"advmod\", \"neg\"] }\n",
        "                }\n",
        "            }\n",
        "            # {\n",
        "            #     \"LEFT_ID\": \"generic_verb\",\n",
        "            #     \"REL_OP\": \">\",\n",
        "            #     \"RIGHT_ID\": \"avoid_negation_and_only\",\n",
        "            #     \"RIGHT_ATTRS\": {\n",
        "            #         \"LEMMA\": { \"IN\": [\"not\", \"only\", \"never\"]},\n",
        "            #         \"POS\": { \"IN\": [\"ADV\", \"PART\"]},\n",
        "            #         \"DEP\": { \"IN\": [\"neg\", \"advmod\"]},\n",
        "            #         \"OP\": \"!\"\n",
        "            #     }\n",
        "            # }\n",
        "        ]\n",
        "        #         \"RIGHT_ATTRS\": {\n",
        "        #             \"LEMMA\": { \"NOT_IN\": [\"not\", \"only\", \"never\"]},\n",
        "        #             # \"POS\": \"PART\", \n",
        "        #             # \"DEP\": \"neg\",\n",
        "        #             # \"OP\": \"!\" # matches exactly zero times\n",
        "        #         }\n",
        "        #     }\n",
        "        # ],\n",
        "        # [\n",
        "        #     {\n",
        "        #         \"RIGHT_ID\": \"can_could_may\",\n",
        "        #         \"RIGHT_ATTRS\": {\"LEMMA\": { \"IN\": [\"can\", \"could\", \"may\"]}, \"POS\": \"AUX\"}\n",
        "        #     },\n",
        "        #     {\n",
        "        #         \"LEFT_ID\": \"can_could_may\",\n",
        "        #         \"REL_OP\": \".\", # next position\n",
        "        #         \"RIGHT_ID\": \"avoid_not_only_never\",\n",
        "        #         \"RIGHT_ATTRS\": {\n",
        "        #             \"LEMMA\": { \"NOT_IN\": [\"not\", \"only\", \"never\"]},\n",
        "        #             # \"POS\": \"PART\", \n",
        "        #             # \"DEP\": \"neg\",\n",
        "        #             # \"OP\": \"!\" # matches exactly zero times\n",
        "        #         }\n",
        "        #     }\n",
        "        # ],\n",
        "        # [\n",
        "        #     {\n",
        "        #         \"RIGHT_ID\": \"decide_choose\",\n",
        "        #         \"RIGHT_ATTRS\": {\"LEMMA\": { \"IN\": [\"decide\", \"choose\", \"opt\"]}, \"POS\": \"VERB\"}\n",
        "        #     },\n",
        "        #     {\n",
        "        #         \"LEFT_ID\": \"can_could_may\",\n",
        "        #         \"REL_OP\": \".\", # right sibling\n",
        "        #         \"RIGHT_ID\": \"avoid_not_only_never\",\n",
        "        #         \"RIGHT_ATTRS\": {\n",
        "        #             \"LEMMA\": { \"NOT_IN\": [\"not\", \"only\", \"never\"]},\n",
        "        #             # \"POS\": \"PART\", \n",
        "        #             # \"DEP\": \"neg\",\n",
        "        #             # \"OP\": \"!\" # matches exactly zero times\n",
        "        #         }\n",
        "        #     }\n",
        "        # ],\n",
        "    ]\n",
        "    can_could_may_without_neg_matcher.add('can_could_may_without_neg', can_could_may_without_neg_patterns)\n",
        "\n",
        "    can_could_may_without_neg_matches = { match[1][0] for match in can_could_may_without_neg_matcher(doc) }\n",
        "    \n",
        "    return can_could_may_matches.difference(can_could_may_without_neg_matches)\n",
        "\n",
        "# text = get_document_by_line(DATASET_FILE_PATH, 130)\n",
        "text = '''you can only take this because it can be outrageous. \n",
        "    you can't take it. you can not also choose. you can never be sure of the result. \n",
        "    you can decide the next thing.'''\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(clean_text(text))\n",
        "print([(i, token.lemma_) for i, token in enumerate(doc)])\n",
        "print(len(doc), len(doc.text))\n",
        "print(get_choices_amount_metric(doc))\n",
        "\n",
        "# displacy.render(doc, style='dep', jupyter=True)"
      ],
      "metadata": {
        "id": "vXvPodfk0ryj",
        "outputId": "7e297388-d2c9-4a81-f13c-6f972d6ba599",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "vXvPodfk0ryj",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 'you'), (1, 'can'), (2, 'only'), (3, 'take'), (4, 'this'), (5, 'because'), (6, 'it'), (7, 'can'), (8, 'be'), (9, 'outrageous'), (10, '.'), (11, 'you'), (12, 'can'), (13, 'not'), (14, 'take'), (15, 'it'), (16, '.'), (17, 'you'), (18, 'can'), (19, 'not'), (20, 'also'), (21, 'choose'), (22, '.'), (23, 'you'), (24, 'can'), (25, 'never'), (26, 'be'), (27, 'sure'), (28, 'of'), (29, 'the'), (30, 'result'), (31, '.'), (32, 'you'), (33, 'can'), (34, 'decide'), (35, 'the'), (36, 'next'), (37, 'thing')]\n",
            "38 163\n",
            "{33, 7}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "import coreferee\n",
        "\n",
        "def _get_new_token_from_resolve(token: spacy.tokens.Token, \n",
        "                                chains: coreferee.data_model.ChainHolder) -> spacy.tokens.Token:\n",
        "    resolved_token = chains.resolve(token)\n",
        "    return token.text_with_ws if resolved_token is None \\\n",
        "                              else ' and '.join([res_token.text_with_ws for res_token in resolved_token])   \n",
        "\n",
        "def _process_doc_for_coref(doc: spacy.tokens.Doc) -> str:\n",
        "    replacement_tokens = []\n",
        "    chains = doc._.coref_chains\n",
        "    new_doc_tokens_text = [_get_new_token_from_resolve(token, chains) for token in doc]\n",
        "\n",
        "    return ''.join(new_doc_tokens_text)\n",
        "\n",
        "def preprocess_texts(texts: List[str]) -> List[str]:\n",
        "    nlp = spacy.load('en_core_web_trf')\n",
        "    nlp.add_pipe(\"coreferee\")\n",
        "\n",
        "    texts = [clean_text(text) for text in texts]\n",
        "    docs = nlp.pipe(texts)\n",
        "\n",
        "    return [_process_doc_for_coref(doc) for doc in docs]\n",
        "        \n",
        "# text = get_document_by_line(DATASET_FILE_PATH, 40)\n",
        "text = '''Although he was very busy with his work, the magical Peter had had enough of it. \n",
        "    He and his wife decided they needed a holiday. \n",
        "    this couple travelled to Spain because it loves the country very much.'''\n",
        "preprocess_texts([text])"
      ],
      "metadata": {
        "id": "jpT4BvSfFWTd"
      },
      "id": "jpT4BvSfFWTd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(clean_text(get_document_by_line(DATASET_FILE_PATH, 155)))\n",
        "doc.text\n",
        "# print(doc[12].dep_)\n",
        "#doc.text.find('Tinners Trail Player')"
      ],
      "metadata": {
        "id": "XojL4wsdmTqI"
      },
      "id": "XojL4wsdmTqI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "from typing import List, Set, Dict\n",
        "from rake_nltk import Rake\n",
        "from nltk.util import ngrams\n",
        "import yake\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "\n",
        "# stopwords = nlp.Defaults.stop_words\n",
        "# rake = Rake(stopwords=stopwords, punctuations={ c for c in punctuation },\n",
        "#             sentence_tokenizer=lambda txt: txt.split('.'))\n",
        "\n",
        "regex_word_within_boundaries = re.compile(r'\\b')\n",
        "MIN_TOKEN_TO_BE_CONSIDERED_COMPONENT = 4\n",
        "MAX_COMPONENTS = 100\n",
        "\n",
        "def _get_ngrams_components(doc: spacy.tokens.Doc, \\\n",
        "                           components: Dict[str, List[spacy.tokens.Token]],\n",
        "                           n_grams: int):\n",
        "    pass\n",
        "\n",
        "\n",
        "def _get_bg_components_by_deps_inspection(doc: spacy.tokens.Doc) -> Dict[str, List[int]]:\n",
        "    words_to_leave_out = ['beginning', 'board', 'book', 'case', 'clarification', 'design', \n",
        "                          'effect', 'end', 'example', 'case', 'game', 'number', \n",
        "                          'overview', 'order', 'play', 'player', 'purpose', 'reference',\n",
        "                          'result', 'rule', 'rulebook', 'section', 'set', 'setup', 'side', 'summary', \n",
        "                          'start', 'step', 'thing', 'type', 'time', 'total', 'use', 'value', 'version', 'way']\n",
        "\n",
        "    possible_components = dict(filter(lambda token: token[0] not in words_to_leave_out and \n",
        "                                      len(token[1]) >= MIN_TOKEN_TO_BE_CONSIDERED_COMPONENT, \n",
        "                                  filter_tokens_as_components(doc).items()))\n",
        "    return possible_components\n",
        "\n",
        "# def _get_lemmas_given_keywords_group(group: str, doc: spacy.tokens.Doc) -> List[str]:\n",
        "#     kw_match = re.search(r'\\b' + group + '\\\\b', doc.text)\n",
        "#     if kw_match is None:\n",
        "#         return []\n",
        "\n",
        "#     group_span = doc.char_span(kw_match.start(0), kw_match.end(0))\n",
        "#     return [token.lemma_.lower() for token in group_span]\n",
        "\n",
        "# def _get_bg_components_by_keyword_analysis(doc: spacy.tokens.Doc, max_keywords: int) -> List[str]:\n",
        "#     kw_extractor = yake.KeywordExtractor(top=max_keywords)\n",
        "#     keywords_info = kw_extractor.extract_keywords(doc.text)\n",
        "#     keyword_groups = [keyword_info[0] for keyword_info in keywords_info if keyword_info[1] < 0.1]\n",
        "\n",
        "#     return [lemma for keyword_group in keyword_groups \n",
        "#             for lemma in _get_lemmas_given_keywords_group(keyword_group, doc)]\n",
        "\n",
        "def get_bg_components(doc: spacy.tokens.Doc) -> Dict[str, List[int]]:\n",
        "    components_by_deps = _get_bg_components_by_deps_inspection(doc)\n",
        "    # print(components_by_deps)\n",
        "    # components_by_kws = _get_bg_components_by_keyword_analysis(doc, len(components_by_deps))\n",
        "    # print(components_by_kws)\n",
        "\n",
        "    # return set(components_by_deps).intersection(set(components_by_kws))\n",
        "    return components_by_deps\n",
        "\n",
        "def get_doc_variance(doc: spacy.tokens.Doc, components_dict: Dict[str, List[int]]) -> float:\n",
        "    '''variance measures how components interleave in the text. This could mean that rules involve\n",
        "    many components and are therefore more complex. variancy is computed using `np.var` on each\n",
        "    component list. the results are normalized by multiplicating for the frequency of the component.\n",
        "    eventually the partial variances are summed together and the result normalized with the \n",
        "    total numbers of tokens.'''\n",
        "    tokens_count = sum(len(token_list) for token_list in components_dict.values())\n",
        "    return sum((len(tokens) / tokens_count) * np.var([token.i for token in tokens])\n",
        "        for tokens in components_dict.values()) / len((doc))\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(clean_text(get_document_by_line(DATASET_FILE_PATH, 138)))\n",
        "print(len(doc.text))\n",
        "components = get_bg_components(doc)\n",
        "print(components)\n",
        "print(get_doc_variance(doc, components))\n",
        "\n",
        "\n",
        "# rake.extract_keywords_from_text(doc.text)\n",
        "# print(rake.get_word_frequency_distribution())\n",
        "# for keyword in rake.get_ranked_phrases_with_scores():\n",
        "#     print(keyword)\n",
        "# print(rake.get_word_degrees())"
      ],
      "metadata": {
        "id": "TKh5Jf-xovbn"
      },
      "id": "TKh5Jf-xovbn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d6596cd-3fd1-4e50-9dce-e6c333667182",
      "metadata": {
        "id": "7d6596cd-3fd1-4e50-9dce-e6c333667182"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple\n",
        "import pandas as pd\n",
        "import ast\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def get_rules_features(id: int, doc: spacy.tokens.Doc) -> Tuple[int, float]:\n",
        "    logger.info(f'processing board game {id}')\n",
        "    rulebook_len = len(doc)\n",
        "    bg_components = get_bg_components(doc)\n",
        "    print(bg_components)\n",
        "\n",
        "    return 0, 0\n",
        "    # rules = get_rules(text)\n",
        "    # rule_count = len(rules)\n",
        "    # return rule_count, len(text) / rule_count\n",
        "\n",
        "def apply_for_rulebook_features(row, docs_dict):\n",
        "    next_doc_info = next(docs_dict)\n",
        "    assert next_doc_info[0] == row.id\n",
        "    return pd.Series(get_rules_features(row.id, next_doc_info[1]), \n",
        "                     index=['rule_count', 'avg_rule_len'])\n",
        "\n",
        "PROCESSED_DATASET_FILE_PATH = 'data/processed_dataset.csv' if WORKING_LOCALLY \\\n",
        "    else '/content/drive/My Drive/Projects/IRBoardGameComplexity/processed_dataset.csv'\n",
        "\n",
        "# ast.literal_eval converts the family column string into a python array\n",
        "# with pd.read_csv(DATASET_FILE_PATH, chunksize=5, converters={ 'info.family': ast.literal_eval }) as reader:\n",
        "#     for df in reader:\n",
        "df_dataset = pd.read_csv(DATASET_FILE_PATH, converters={ 'info.family': ast.literal_eval }, nrows=1)\n",
        "remove_columns_prefix(df_dataset)\n",
        "docs_dict = zip(df_dataset['id'].values, \n",
        "                nlp.pipe(map(clean_text, df_dataset['rulebook'].values)))\n",
        "\n",
        "df_rules_features = df_dataset.apply(lambda x: apply_for_rulebook_features(x, docs_dict),\n",
        "                                     axis='columns')\n",
        "df_features = df_dataset[['averageweight', 'playingtime', 'family']].join(df_rules_features)\n",
        "        \n",
        "# one-hot encoding \"family\" field \n",
        "# from https://stackoverflow.com/questions/71401193/one-hot-encoding-in-python-for-array-values-in-a-dataframe\n",
        "df_features = df_features.join(df_features.pop('family').apply('|'.join).str.get_dummies())\n",
        "df_features.head()\n",
        "\n",
        "# df_features.to_csv(PROCESSED_DATASET_FILE_PATH, header=True, index=False, mode='w')    \n",
        "# if not WORKING_LOCALLY:\n",
        "#     drive.flush_and_unmount()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}